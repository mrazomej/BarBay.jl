var documenterSearchIndex = {"docs":
[{"location":"mcmc/#mcmc","page":"mcmc","title":"mcmc","text":"","category":"section"},{"location":"mcmc/","page":"mcmc","title":"mcmc","text":"The mcmc module contains functions necessary to fit the statistical model via a Markov Chain Monte Carlo sampling-based method. MCMC is guaranteed to converge to the \"true\" posterior distribution. Therefore, for small number of barcodes (≈ 100-250) we recommend trying this approach. To scale the analysis, please check the vi module for variational inference.","category":"page"},{"location":"mcmc/","page":"mcmc","title":"mcmc","text":"Modules = [BarBay.mcmc]\nOrder   = [:function, :type]","category":"page"},{"location":"mcmc/#BarBay.mcmc.mcmc_sample-Tuple{}","page":"mcmc","title":"BarBay.mcmc.mcmc_sample","text":"Function to sample the joint posterior distribution for the fitness value of all     mutant and neutral linages given a time-series barcode count.\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode   sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage\n\nor not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputname::String: String to be used to name the .jld2 output file.\nmodel::Function: Turing.jl model defining the posterior distribution from   which to sample (see BarBay.model module). This function must take   as the first four inputs the following:\nR̲̲::Array{Int64}:: 2 or 3D array containing the raw barcode counts for all tracked genotypes. The dimensions of this array represent:\ndim=1: time.\ndim=2: genotype.\ndim=3 (optional): experimental repeats\nn̲ₜ::VecOrMat{Int64}: Array with the total number of barcode counts for   each time point (on each experimental repeat, if necessary).\nn_neutral::Int: Number of neutral lineages.\nn_bc::Int: Number of neutral lineages.\n\nOptional Keyword Arguments\n\nmodel_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the   model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point   at which measurements were done. The column may contain any type of entry as   long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw   barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether   the barcode belongs to a neutral lineage or not. The column must contain   entries of type Bool.\nrep_col::Union{Nothing,Symbol}=nothing: Optional column in tidy dataframe to specify the experimental repeat for each observation.\nrm_T0::Bool=false: Optional argument to remove the first time point from the   inference. Commonly, the data from this first time point is of much lower   quality. Therefore, removing this first time point might result in a better   inference.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler   to be used.\nensemble::Turing.AbstractMCMC.AbstractMCMCEnsemble=Turing.MCMCSerial():\n\nSampling modality to be used. Options are:     - Turing.MCMCSerial()     - Turing.MCMCThreads()     - Turing.MCMCDistributed()\n\nverbose::Bool=true: Boolean indicating if the function should print partial   progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"contributing/#contributing","page":"contributing","title":"contributing","text":"","category":"section"},{"location":"contributing/","page":"contributing","title":"contributing","text":"warning: Disclaimer\nThe authors of this package have no formal training in software engineering. But we are eager to learn about best practices and are very open to suggestions via GitHub issues or PRs!","category":"page"},{"location":"contributing/","page":"contributing","title":"contributing","text":"We welcome contributions to the package via pull requests. One such example could be adding a new variation of the base model to the model module. All models within BarBay.jl that can be fit with the mcmc or the vi modules are standardized to take as the first four arguments the following:","category":"page"},{"location":"contributing/","page":"contributing","title":"contributing","text":"R̲̲: Array-like object that contains the raw barcode counts. These can be either a matrix, a tensor, or a list of arrays. The main feature is that each \"face\" of the array-like object represents a matrix where each column contains the time series data for a single barcode. Here are some examples of the types used in different models:\nR̲̲::Matrix{Int64}: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage.\nR̲̲::Array{Int64, 3}:: T × B × R where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each slice in the R axis, each column represents the barcode count trajectory for a single lineage.\nR̲̲::Vector{Matrix{Int64}}:: Length R vector wth T × B matrices   where T is the number of time points in the data set, B is the number   of barcodes, and R is the number of experimental replicates. For each   matrix in the vector, each column represents the barcode count trajectory   for a single lineage.\nn̲ₜ: Array-like object with the total number of barcode counts for each time point. As with R̲̲, the structure of n̲ₜ must be adapted for the needs of your data structure. Here are some examples of the types used in different models:\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)).\nn̲ₜ::Vector{Vector{Int64}}: Vector of vectors with the total number of barcode counts for each time point on each replicate. NOTE: This vector must be equivalent to computing vec.(sum.(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset. \nn_bc::Int: Number of mutant lineages in dataset.","category":"page"},{"location":"contributing/","page":"contributing","title":"contributing","text":"The rest of the arguments fed to the model function must be optional keyword arguments. This means that they should be listed after the semi-colon that separates the first four inputs from the rest and they should have a default value. As an example, take a look at the definition of the input arguments for one of the base models:","category":"page"},{"location":"contributing/","page":"contributing","title":"contributing","text":"Turing.@model function fitness_normal(\n    R̲̲::Matrix{Int64},\n    n̲ₜ::Vector{Int64},\n    n_neutral::Int,\n    n_bc::Int;\n    s_pop_prior::VecOrMat{Float64}=[0.0, 2.0],\n    logσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0],\n    s_bc_prior::VecOrMat{Float64}=[0.0, 2.0],\n    logσ_bc_prior::VecOrMat{Float64}=[0.0, 1.0],\n    logλ_prior::VecOrMat{Float64}=[3.0, 3.0]\n)","category":"page"},{"location":"contributing/","page":"contributing","title":"contributing","text":"Furthermore, the four inputs to the model are automatically generated within the mcmc and the vi modules via the data_to_arrays function from the utils module. Take a look at the source code for this function to familiarize yourself with it. In case this is inconvenient, please open an issue in the GitHub repository and we will be happy to make changes to adapt the package to your needs!","category":"page"},{"location":"contributing/","page":"contributing","title":"contributing","text":"If your defined model follows these standards, you should be able to fit it with the tools provided within this package. Here are some resources to get familiar with the model structure within Turing.jl:","category":"page"},{"location":"contributing/","page":"contributing","title":"contributing","text":"Getting Started with Turing.jl\nBayesian Statistics using Julia and Turing","category":"page"},{"location":"contributing/","page":"contributing","title":"contributing","text":"Furthermore, we recommend looking at the source code within this package GitHub repository. Every function and model is highly annotated and can serve as a guide to get you going!","category":"page"},{"location":"examples/#examples","page":"examples","title":"examples","text":"","category":"section"},{"location":"examples/","page":"examples","title":"examples","text":"This section contains multiple example scripts to run inference using the models (included in the model module) for different experimental designs. These are meant to serve as a guide for new users to get their analysis running ASAP.","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"We invite the users to check the full documentation to adapt the inference to their specific needs. Also, we invite the users to open an issue in the GitHub repository to report bugs or ask questions.","category":"page"},{"location":"examples/#General-package-imports","page":"examples","title":"General package imports","text":"","category":"section"},{"location":"examples/","page":"examples","title":"examples","text":"All of the examples listed below make use of the same libraries. Therefore, we suggest adding this at the beginning of all inference scripts.","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"# Import project package\nimport BayesFitUtils\n\n# Import library package\nimport BarBay\n\n# Import libraries to manipulate data\nimport DataFrames as DF\nimport CSV\n\n# Import library to perform Bayesian inference\nimport Turing\n\n# Import AutoDiff backend\nusing ReverseDiff\n\n# Import Memoization\nusing Memoization\n\n# Impor statistical libraries\nimport Random\nimport StatsBase\nimport Distributions\n\nRandom.seed!(42)\n\n# Set AutoDiff backend\nTuring.setadbackend(:reversediff)\n# Allow system to generate cache to speed up computation\nTuring.setrdcache(true)","category":"page"},{"location":"examples/#Single-dataset-single-environment-variational-inference","page":"examples","title":"Single dataset single environment variational inference","text":"","category":"section"},{"location":"examples/","page":"examples","title":"examples","text":"For the case where there is a single dataset produced with a series of growth-dilution cycles over a single environment.","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"The dataset should look something like","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"| time | barcode    | count | neutral | freq        |\n|------|------------|-------|---------|-------------|\n| 3    | neutral025 | 12478 | TRUE    | 0.000543716 |\n| 4    | neutral025 | 10252 | TRUE    | 0.00034368  |\n| 5    | neutral025 | 2883  | TRUE    | 6.74E-05    |\n| 1    | mut001     | 1044  | FALSE   | 7.97E-05    |\n| 2    | mut001     | 2010  | FALSE   | 0.000121885 |\n| 3    | mut001     | 766   | FALSE   | 3.34E-05    |\n| 4    | mut001     | 216   | FALSE   | 7.24E-06    |\n| 5    | mut001     | 120   | FALSE   | 2.81E-06    |\n| 1    | mut002     | 51484 | FALSE   | 0.003930243 |","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"The script to analyze the data then looks like","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Define ADVI hyerparameters\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Define number of samples and steps\nn_samples = 1\nn_steps = 3_000\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Generate output directories\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Generate output directory \nif !isdir(\"./output/\")\n    mkdir(\"./output/\")\nend # if\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Loading the data\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nprintln(\"Loading data...\")\n\n# Import data\ndata = CSV.read(\n    \"path/to/data/tidy_data.csv\", DF.DataFrame\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Obtain priors on expected errors from neutral measurements\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Compute naive priors from neutral strains\nnaive_priors = BarBay.stats.naive_prior(data)\n\n# Select standard deviation parameters\ns_pop_prior = hcat(\n    naive_priors[:s_pop_prior],\n    repeat([0.05], length(naive_priors[:s_pop_prior]))\n)\n\nlogσ_pop_prior = hcat(\n    naive_priors[:logσ_pop_prior],\n    repeat([1.0], length(naive_priors[:logσ_pop_prior]))\n)\n\nlogσ_bc_prior = [StatsBase.mean(naive_priors[:logσ_pop_prior]), 1.0]\n\nlogλ_prior = hcat(\n    naive_priors[:logλ_prior],\n    repeat([3.0], length(naive_priors[:logλ_prior]))\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Define ADVI function parameters\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nparam = Dict(\n    :data => data,\n    :outputname => \"./output/advi_meanfield_\" *\n                   \"$(lpad(n_samples, 2, \"0\"))samples_$(n_steps)steps\",\n    :model => BarBay.model.fitness_normal,\n    :model_kwargs => Dict(\n        :s_pop_prior => s_pop_prior,\n        :logσ_pop_prior => logσ_pop_prior,\n        :logσ_bc_prior => logσ_bc_prior,\n        :s_bc_prior => [0.0, 1.0],\n        :logλ_prior => logλ_prior,\n    ),\n    :advi => Turing.ADVI(n_samples, n_steps),\n    :opt => Turing.TruncatedADAGrad(),\n    :fullrank => false\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Perform optimization\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Run inference\nprintln(\"Running Variational Inference...\")\n@time BarBay.vi.advi(; param...)","category":"page"},{"location":"examples/#Single-dataset-single-environment-MCMC-sampling","page":"examples","title":"Single dataset single environment MCMC sampling","text":"","category":"section"},{"location":"examples/","page":"examples","title":"examples","text":"If the number of barcodes is relatively small, one can try a more exact sampling of the posterior with MCMC. BarBay is structured such that the changes from fitting a model with ADVI vs MCMC are minimal. Here is an example script to fit the same dataset as before using Dynamic HMC:","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Define MCMC hyerparameters\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nn_steps = 3_000\nn_walkers = 4\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Generate output directories\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Generate output directory \nif !isdir(\"./output/\")\n    mkdir(\"./output/\")\nend # if\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Loading the data\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nprintln(\"Loading data...\")\n\n# Import data\ndata = CSV.read(\n    \"path/to/data/tidy_data.csv\", DF.DataFrame\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Obtain priors on expected errors from neutral measurements\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Compute naive priors from neutral strains\nnaive_priors = BarBay.stats.naive_prior(data)\n\n# Select standard deviation parameters\ns_pop_prior = hcat(\n    naive_priors[:s_pop_prior],\n    repeat([0.05], length(naive_priors[:s_pop_prior]))\n)\n\nlogσ_pop_prior = hcat(\n    naive_priors[:logσ_pop_prior],\n    repeat([1.0], length(naive_priors[:logσ_pop_prior]))\n)\n\nlogσ_bc_prior = [StatsBase.mean(naive_priors[:logσ_pop_prior]), 1.0]\n\nlogλ_prior = hcat(\n    naive_priors[:logλ_prior],\n    repeat([3.0], length(naive_priors[:logλ_prior]))\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Initialize MCMC sampling\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nprintln(\"Initializing MCMC sampling...\\n\")\n\n# Define function parameters\nparam = Dict(\n    :data => data,\n    :n_walkers => n_walkers,\n    :n_steps => n_steps,\n    :outputname => \"./output/chain_joint_fitness_$(n_steps)steps_$(lpad(n_walkers, 2, \"0\"))walkers\",\n    :model => BarBay.model.fitness_normal,\n    :model_kwargs => Dict(\n        :s_pop_prior => s_pop_prior,\n        :logσ_pop_prior => logσ_pop_prior,\n        :logσ_bc_prior => logσ_bc_prior,\n        :s_bc_prior => [0.0, 1.0],\n        :logλ_prior => logλ_prior,\n    ),\n    :sampler => Turing.externalsampler(DynamicHMC.NUTS()),\n    :ensemble => Turing.MCMCThreads(),\n    :rm_T0 => false,\n)\n\n# Run inference\nprintln(\"Running Inference...\")\n\n@time BarBay.mcmc.mcmc_sample(; param...)","category":"page"},{"location":"examples/#Multi-environment-single-dataset-variational-inference","page":"examples","title":"Multi-environment single dataset variational inference","text":"","category":"section"},{"location":"examples/","page":"examples","title":"examples","text":"When dealing with an experiment where the growth-dilution cycles were done into different environments, the data should include a column indicating the  environment label. The dataset then looks something like","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"| time | env | barcode    | count | neutral | freq        |\n|------|-----|------------|-------|---------|-------------|\n| 1    | 1   | neutral100 | 7327  | TRUE    | 0.000399781 |\n| 2    | 1   | neutral100 | 4034  | TRUE    | 0.000228517 |\n| 3    | 2   | neutral100 | 5135  | TRUE    | 0.000257352 |\n| 4    | 3   | neutral100 | 2011  | TRUE    | 6.80E-05    |\n| 5    | 1   | neutral100 | 1225  | TRUE    | 3.39E-05    |\n| 6    | 2   | neutral100 | 693   | TRUE    | 1.93E-05    |\n| 7    | 3   | neutral100 | 152   | TRUE    | 4.08E-06    |\n| 1    | 1   | mut001     | 268   | FALSE   | 1.46E-05    |\n| 2    | 1   | mut001     | 187   | FALSE   | 1.06E-05    |","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"A basic script to analyze this dataset then takes the form","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Define ADVI hyerparameters\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Define number of samples and steps\nn_samples = 1\nn_steps = 10_000\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Generate output directories\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Generate output directory \nif !isdir(\"./output/\")\n    mkdir(\"./output/\")\nend # if\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Loading the data\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nprintln(\"Loading data...\")\n\n# Import data\ndata = CSV.read(\"path/to/data/tidy_data.csv\", DF.DataFrame)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Obtain priors on expected errors from neutral measurements\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Compute naive priors from neutral strains\nnaive_priors = BarBay.stats.naive_prior(data; pseudocount=1)\n\n# Select standard deviation parameters\ns_pop_prior = hcat(\n    naive_priors[:s_pop_prior],\n    repeat([0.05], length(naive_priors[:s_pop_prior]))\n)\n\nlogσ_pop_prior = hcat(\n    naive_priors[:logσ_pop_prior],\n    repeat([1.0], length(naive_priors[:logσ_pop_prior]))\n)\n\nlogσ_bc_prior = [StatsBase.mean(naive_priors[:logσ_pop_prior]), 1.0]\n\nlogλ_prior = hcat(\n    naive_priors[:logλ_prior],\n    repeat([3.0], length(naive_priors[:logλ_prior]))\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Define ADVI function parameters\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nparam = Dict(\n    :data => data,\n    :outputname => \"./output/advi_meanfield_$(lpad(n_samples, 2, \"0\"))samples_$(n_steps)steps\",\n    :model => BarBay.model.multienv_fitness_normal,\n    :model_kwargs => Dict(\n        :s_pop_prior => s_pop_prior,\n        :logσ_pop_prior => logσ_pop_prior,\n        :logσ_bc_prior => logσ_bc_prior,\n        :s_bc_prior => [0.0, 1.0],\n        :logλ_prior => logλ_prior,\n    ),\n    :env_col => :env,\n    :advi => Turing.ADVI(n_samples, n_steps),\n    :opt => Turing.TruncatedADAGrad(),\n    :fullrank => false\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Perform optimization\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Run inference\nprintln(\"Running Variational Inference...\")\n@time BarBay.vi.advi(; param...)","category":"page"},{"location":"examples/#Hierarchical-model-for-multiple-experimental-replicates-variational-inference","page":"examples","title":"Hierarchical model for multiple experimental replicates variational inference","text":"","category":"section"},{"location":"examples/","page":"examples","title":"examples","text":"If there are more than one experimental replicates, the dataset must include a column indicating the replicate ID for each observation. The dataset ends up looking like","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"| time | barcode    | count | neutral | count_sum | freq        | rep  |\n|------|------------|-------|---------|-----------|-------------|------|\n| 1    | neutral001 | 9967  | TRUE    | 19321304  | 0.000515855 | R1   |\n| 2    | neutral001 | 3749  | TRUE    | 18224218  | 0.000205715 | R1   |\n| 3    | neutral001 | 3516  | TRUE    | 23317980  | 0.000150785 | R1   |\n| 4    | neutral001 | 2217  | TRUE    | 31261050  | 7.09E-05    | R1   |\n| 5    | neutral001 | 1027  | TRUE    | 38335591  | 2.68E-05    | R1   |\n| 1    | neutral002 | 8676  | TRUE    | 19321304  | 0.000449038 | R1   |\n| 2    | neutral002 | 6019  | TRUE    | 18224218  | 0.000330275 | R1   |\n| 3    | neutral002 | 2245  | TRUE    | 23317980  | 9.63E-05    | R1   |\n| 4    | neutral002 | 2179  | TRUE    | 31261050  | 6.97E-05    | R1   |","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"To analyze multiple experimental replicates jointly, we can use a hierarchical model. The basic script to implement this looks something like","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Define ADVI hyerparameters\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Define number of samples and steps\nn_samples = 1\nn_steps = 10_000\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Generate output directories\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Generate output directory \nif !isdir(\"./output/\")\n    mkdir(\"./output/\")\nend # if\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Loading the data\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nprintln(\"Loading data...\")\n\n# Import data\ndata = CSV.read(\"path/to/data/tidy_data.csv\", DF.DataFrame)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Obtain priors on expected errors from neutral measurements\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Compute naive priors from neutral strains\nnaive_priors = BarBay.stats.naive_prior(data; rep_col=:rep, pseudocount=1)\n\n# Select standard deviation parameters\ns_pop_prior = hcat(\n    naive_priors[:s_pop_prior],\n    repeat([0.05], length(naive_priors[:s_pop_prior]))\n)\n\nlogσ_pop_prior = hcat(\n    naive_priors[:logσ_pop_prior],\n    repeat([1.0], length(naive_priors[:logσ_pop_prior]))\n)\n\nlogσ_bc_prior = [StatsBase.mean(naive_priors[:logσ_pop_prior]), 1.0]\n\nlogλ_prior = hcat(\n    naive_priors[:logλ_prior],\n    repeat([3.0], length(naive_priors[:logλ_prior]))\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Define ADVI function parameters\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nparam = Dict(\n    :data => data,\n    :outputname => \"./output/advi_meanfield_\" *\n                   \"$(lpad(n_samples, 2, \"0\"))samples_$(n_steps)steps\",\n    :model => BarBay.model.replicate_fitness_normal,\n    :model_kwargs => Dict(\n        :s_pop_prior => s_pop_prior,\n        :logσ_pop_prior => logσ_pop_prior,\n        :logσ_bc_prior => logσ_bc_prior,\n        :s_bc_prior => [0.0, 1.0],\n        :logλ_prior => logλ_prior,\n        :logτ_prior => [-2.0, 0.5],\n    ),\n    :advi => Turing.ADVI(n_samples, n_steps),\n    :opt => Turing.TruncatedADAGrad(),\n    :rep_col => :rep,\n    :fullrank => false\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Perform optimization\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Run inference\nprintln(\"Running Variational Inference...\")\n@time BarBay.vi.advi(; param...)","category":"page"},{"location":"examples/#Hierarchical-model-for-multiple-barcodes-mapping-to-same-genotype-variational-inference","page":"examples","title":"Hierarchical model for multiple barcodes mapping to same genotype variational inference","text":"","category":"section"},{"location":"examples/","page":"examples","title":"examples","text":"When multiple barcodes map to the same genotype within a single experiment, the dataset must include a column indicating the genotype each barcode belongs to. The dataset ends up looking something like","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"| time | barcode    | count | neutral | count_sum | freq         | genotype     |\n|------|------------|-------|---------|-----------|--------------|--------------|\n| 1    | neutral001 | 6649  | TRUE    | 17418514  | 0.00038172   | genotype000  |\n| 2    | neutral001 | 6245  | TRUE    | 16007352  | 0.000390133  | genotype000  |\n| 3    | neutral001 | 6323  | TRUE    | 22075763  | 0.000286423  | genotype000  |\n| 4    | neutral001 | 2345  | TRUE    | 27743357  | 8.45E-05     | genotype000  |\n| 5    | neutral001 | 1379  | TRUE    | 34253492  | 4.03E-05     | genotype000  |\n| 1    | neutral002 | 5160  | TRUE    | 17418514  | 0.000296237  | genotype000  |\n| 2    | neutral002 | 4078  | TRUE    | 16007352  | 0.000254758  | genotype000  |\n| 3    | neutral002 | 3386  | TRUE    | 22075763  | 0.000153381  | genotype000  |\n| 4    | neutral002 | 2821  | TRUE    | 27743357  | 0.000101682  | genotype000  |","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"As with experimental replicates, we can implement a hierarchical model for this experimental design. The basic script to implement this looks like","category":"page"},{"location":"examples/","page":"examples","title":"examples","text":"# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Define ADVI hyerparameters\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Define number of samples and steps\nn_samples = 1\nn_steps = 10_000\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Generate output directories\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Generate output directory \nif !isdir(\"./output/\")\n    mkdir(\"./output/\")\nend # if\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Loading the data\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nprintln(\"Loading data...\")\n\n# Import data\ndata = CSV.read(\"path/to/data/tidy_data.csv\", DF.DataFrame)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Obtain priors on expected errors from neutral measurements\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Compute naive priors from neutral strains\nnaive_priors = BarBay.stats.naive_prior(data; pseudocount=1)\n\n# Select standard deviation parameters\ns_pop_prior = hcat(\n    naive_priors[:s_pop_prior],\n    repeat([0.05], length(naive_priors[:s_pop_prior]))\n)\n\nlogσ_pop_prior = hcat(\n    naive_priors[:logσ_pop_prior],\n    repeat([1.0], length(naive_priors[:logσ_pop_prior]))\n)\n\nlogσ_bc_prior = [StatsBase.mean(naive_priors[:logσ_pop_prior]), 1.0]\n\nlogλ_prior = hcat(\n    naive_priors[:logλ_prior],\n    repeat([3.0], length(naive_priors[:logλ_prior]))\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Define ADVI function parameters\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\nparam = Dict(\n    :data => data,\n    :outputname => \"./output/advi_meanfield_hierarchicalgenotypes_\" *\n                   \"$(lpad(n_samples, 2, \"0\"))samples_$(n_steps)steps\",\n    :model => BarBay.model.genotype_fitness_normal,\n    :model_kwargs => Dict(\n        :s_pop_prior => s_pop_prior,\n        :logσ_pop_prior => logσ_pop_prior,\n        :logσ_bc_prior => logσ_bc_prior,\n        :s_bc_prior => [0.0, 1.0],\n        :logλ_prior => logλ_prior,\n    ),\n    :genotype_col => :genotype,\n    :advi => Turing.ADVI(n_samples, n_steps),\n    :opt => Turing.TruncatedADAGrad(),\n    :fullrank => false\n)\n\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n# Perform optimization\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n# Run inference\nprintln(\"Running Variational Inference...\")\n@time dist = BarBay.vi.advi(; param...)","category":"page"},{"location":"model/#model","page":"model","title":"model","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"In this section, we list the available models to be fit with either mcmc or vi. To see examples on how to implement these models, please check the examples tab.","category":"page"},{"location":"model/#Single-dataset-single-environment","page":"model","title":"Single-dataset single-environment","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"BarBay.model.fitness_normal","category":"page"},{"location":"model/#BarBay.model.fitness_normal","page":"model","title":"BarBay.model.fitness_normal","text":"fitness_normal(R̲̲::Matrix{Int64}, n̲ₜ::Vector{Int64}, n_neutral::Int,                   n_bc::Int; kwargs...)\n\nDefines a model to estimate fitness effects in a competitive fitness experiment across growth-dilution cycles.\n\nModel summary\n\nPrior on population mean fitness at time t, π(sₜ)\n\nsₜ ~ Normal(params=s_pop_prior)\n\nPrior on population log mean fitness associated error at time t, π(logσₜ)\n\nlogσₜ ~ Normal(params=logσ_pop_prior)\n\nPrior on non-neutral relative fitness for barcoe m, π(s⁽ᵐ⁾)\n\ns⁽ᵐ⁾ ~ Normal(params=s_bc_prior)\n\nPrior on non-neutral log relative fitness associated error for barcode m π(logσ⁽ᵐ⁾)\n\nlogσ⁽ᵐ⁾ ~ Normal(params=logσ_bc_prior)\n\nPrior on log Poisson distribtion parameters for barcode m at time t , π(logλₜᵣ⁽ᵐ⁾) \n\nlogλₜ⁽ᵐ⁾ ~ Normal(params=logλ_prior)\n\nProbability of total number of barcodes read given the Poisson distribution parameters at time t π(nₜ | logλ̲ₜ)\n\nnₜ ~ Poisson(∑ₘ exp(λₜ⁽ᵐ⁾))\n\nBarcode j frequency at time t (deterministic relationship from the Poisson parameters)\n\nfₜ⁽ʲ⁾ = λₜ⁽ʲ⁾ / ∑ₖ λₜ⁽ᵏ⁾\n\nlog frequency ratio for barcode j at time t (deterministic relationship from barcode frequencies)\n\nlogγₜ⁽ʲ⁾ = log(f₍ₜ₊₁₎⁽ʲ⁾ / fₜ⁽ʲ⁾)\n\nProbability of number of reads at time t for all barcodes given the total number of reads and the barcode frequencies π(r̲ₜ | nₜ, f̲ₜ)\n\nr̲ₜ ~ Multinomial(nₜ, f̲ₜ)\n\nProbability of neutral barcodes frequency ratio for barcode n at time t π(logγₜ⁽ⁿ⁾| sₜ, σₜ)\n\nlogγₜ⁽ⁿ⁾ ~ Normal(μ = -sₜ, σ = exp(logσₜ))\n\nProbability of non-neutral barcodes frequency ratio for barcode m at time t π(logγₜ⁽ᵐ⁾| s⁽ᵐ⁾, σ⁽ᵐ⁾, sₜ)\n\nlogγₜ⁽ᵐ⁾ ~ Normal(μ = s⁽ᵐ⁾ - sₜ, σ = exp(logσ⁽ᵐ⁾))\n\nArguments\n\nR̲̲::Matrix{Int64}: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset. \nn_bc::Int: Number of mutant lineages in dataset.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of adjacent time points in dataset.\nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: σ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness log-error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of adjacent time points in dataset.  \ns_bc_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_bc_prior[1] = mean, s_bc_prior[2] = standard deviation, Matrix: s_bc_prior[:, 1] = mean, s_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_bc_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of unique environments in the dataset.\nlogσ_bc_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_bc_prior[1] = mean, logσ_bc_prior[2] = standard deviation, Matrix: logσ_bc_prior[:, 1] = mean, logσ_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness log-error utilized in the log-likelihood function. If typeof(logσ_bc_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of unique environments in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the log of the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(λ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint.\nMutant fitness effects.\nλ dispersion parameters per barcode and timepoint.\n\nNotes\n\nModels fitness effects as normally distributed. \nUtilizes a Poisson observation model for barcode counts.\nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\n","category":"function"},{"location":"model/#Single-dataset-multi-environment","page":"model","title":"Single-dataset multi-environment","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"BarBay.model.multienv_fitness_normal","category":"page"},{"location":"model/#BarBay.model.multienv_fitness_normal","page":"model","title":"BarBay.model.multienv_fitness_normal","text":"multienv_fitness_normal(R̲̲::Matrix{Int64}, n̲ₜ::Vector{Int64},                           n_neutral::Int, n_bc::Int; kwargs...)\n\nDefines a model to estimate fitness effects in a competitive fitness experiment with different environments across growth-dilution cycles.\n\nModel summary\n\nPrior on population mean fitness at time t, π(sₜ)\n\nsₜ ~ Normal(params=s_pop_prior)\n\nPrior on population log mean fitness associated error at time t, π(logσₜ)\n\nlogσₜ ~ Normal(params=logσ_pop_prior)\n\nPrior on non-neutral relative fitness for barcode m in environment i π(sᵢ⁽ᵐ⁾)\n\nsᵢ⁽ᵐ⁾ ~ Normal(params=s_bc_prior)\n\nPrior on non-neutral log relative fitness associated error for barcode m in environment i π(logσᵢ⁽ᵐ⁾)\n\nlogσᵢ⁽ᵐ⁾ ~ Normal(params=logσ_bc_prior)\n\nPrior on log Poisson distribtion parameters for barcode m at time t , π(logλₜᵣ⁽ᵐ⁾) \n\nlogλₜ⁽ᵐ⁾ ~ Normal(params=logλ_prior)\n\nProbability of total number of barcodes read given the Poisson distribution parameters at time t π(nₜ | logλ̲ₜ)\n\nnₜ ~ Poisson(∑ₘ exp(λₜ⁽ᵐ⁾))\n\nBarcode j frequency at time t (deterministic relationship from the Poisson parameters)\n\nfₜ⁽ʲ⁾ = λₜ⁽ʲ⁾ / ∑ₖ λₜ⁽ᵏ⁾\n\nlog frequency ratio for barcode j at time t (deterministic relationship from barcode frequencies)\n\nlogγₜ⁽ʲ⁾ = log(f₍ₜ₊₁₎⁽ʲ⁾ / fₜ⁽ʲ⁾)\n\nProbability of number of reads at time t for all barcodes given the total number of reads and the barcode frequencies π(r̲ₜ | nₜ, f̲ₜ)\n\nr̲ₜ ~ Multinomial(nₜ, f̲ₜ)\n\nProbability of neutral barcodes frequency ratio for barcode n at time t π(logγₜ⁽ⁿ⁾| sₜ, logσₜ)\n\nlogγₜ⁽ⁿ⁾ ~ Normal(μ = -sₜ, σ = exp(logσₜ))\n\nProbability of non-neutral barcodes frequency ratios π(logγₜ⁽ᵐ⁾| s⁽ᵐ⁾, logσ⁽ᵐ⁾, sₜ). Note: This is done grouping by corresponding environment such that if time t is associated with environment i, sᵢ⁽ᵐ⁾ is used as the fitness value.\n\nlogγₜ⁽ᵐ⁾ ~ Normal(μ = sᵢ⁽ᵐ⁾ - sₜ, σ = exp(σ⁽ᵐ⁾))\n\nArguments\n\nR̲̲::Matrix{Int64}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset. \nn_bc::Int: Number of mutant lineages in dataset.\n\nKeyword Arguments\n\nenvs::Vector{<:Any}: List of environments for each time point in dataset. NOTE: The length must be equal to that of n̲t to have one environment per time point.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of adjacent time points in dataset.\nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: σ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness log-error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of adjacent time points in dataset.  \ns_bc_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_bc_prior[1] = mean, s_bc_prior[2] = standard deviation, Matrix: s_bc_prior[:, 1] = mean, s_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_bc_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of unique environments in the dataset.\nlogσ_bc_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_bc_prior[1] = mean, logσ_bc_prior[2] = standard deviation, Matrix: logσ_bc_prior[:, 1] = mean, logσ_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness log-error utilized in the log-likelihood function. If typeof(logσ_bc_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of unique environments in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the log of the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(λ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint\nMutant fitness effects per environment\nλ dispersion parameters per barcode and timepoint\n\nNotes\n\nModels fitness effects as normally distributed. \nUtilizes a Poisson observation model for barcode counts.\nCan estimate time-varying and environment-specific fitness effects.  \nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\n","category":"function"},{"location":"model/#Single-dataset-hierarchical-model-on-genotypes","page":"model","title":"Single-dataset hierarchical model on genotypes","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"BarBay.model.genotype_fitness_normal","category":"page"},{"location":"model/#BarBay.model.genotype_fitness_normal","page":"model","title":"BarBay.model.genotype_fitness_normal","text":"genotype_fitness_normal(R̲̲::Vector{Matrix{Int64}}, n̲ₜ::Vector{Vector{Int64}},                         n_neutral::Int, n_bc::Int; kwargs...)\n\nDefines a hierarchical model to estimate fitness effects in a competitive fitness experiment where multiple barcodes belong to a specific \"genotype.\" This means that different barcodes are grouped together through a fitness hyperparameter where each barcode samples from the distribution of this hyperparameter.\n\nModel summary\n\nPrior on population mean fitness at time t, π(sₜ)\n\nsₜ ~ Normal(params=s_pop_prior)\n\nPrior on population log mean fitness associated error π(logσₜ)\n\nlogσₜ ~ Normal(params=logσ_pop_prior)\n\nPrior on non-neutral relative hyper-fitness for genotype i π(θᵢ)\n\nθᵢ ~ Normal(params=s_bc_prior)\n\nprior on non-centered samples that allow local fitness to vary in the positive and negative direction for genotype i π(θ̃ᵢ⁽ᵐ⁾). Note, this is a standard normal with mean zero and standard deviation one. \n\nθ̃ᵢ⁽ᵐ⁾ ~ Normal(μ = 0, σ = 1)\n\nprior on log deviations of local fitness of barcode m from hyper-fitness for genotype i π(logτᵢ⁽ᵐ⁾)\n\nlogτᵢ⁽ᵐ⁾ ~ Normal(params=logτ_prior)\n\nlocal relative fitness for non-neutral barcode m with genotype i (deterministic relationship from hyper-priors)\n\nsᵢ⁽ᵐ⁾ = θᵢ + θ̃ᵢ⁽ᵐ⁾ * exp(logτᵢ⁽ᵐ⁾)\n\nPrior on non-neutral log relative fitness associated error for non-neutral barcode m with genotype i, π(logσᵢ⁽ᵐ⁾)\n\nlogσᵢ⁽ᵐ⁾ ~ Normal(params=logσ_bc_prior)\n\nPrior on log Poisson distribtion parameters for barcode m at time t in replicate r, π(logλₜᵣ⁽ᵐ⁾) \n\nlogλₜᵣ⁽ᵐ⁾ ~ Normal(params=logλ_prior)\n\nProbability of total number of barcodes read given the Poisson distribution parameters π(nₜ | logλ̲ₜ)\n\nnₜ ~ Poisson(∑ₖ exp(λₜ⁽ᵏ⁾))\n\nBarcode j frequency at time t (deterministic relationship from the Poisson parameters)\n\nfₜ⁽ʲ⁾ = λₜ⁽ʲ⁾ / ∑ₖ λₜ⁽ᵏ⁾\n\nlog frequency ratio for barcode j at time t (deterministic relationship from barcode frequencies)\n\nlogγₜ⁽ʲ⁾ = log(fₜ₊₁⁽ʲ⁾ / fₜ⁽ʲ⁾)\n\nProbability of number of reads at time t for all barcodes given the total number of reads and the barcode frequencies π(r̲ₜ | nₜ, f̲ₜ)\n\nr̲ₜ ~ Multinomial(nₜ, f̲ₜ)\n\nProbability of neutral barcodes n frequency ratio at time t π(logγₜ⁽ⁿ⁾| sₜ, logσₜ)\n\nlogγₜ⁽ⁿ⁾ ~ Normal(μ = -sₜ, σ = exp(logσₜ))\n\nProbability of non-neutral barcode m with genotype i frequency ratio at time t π(logγₜ⁽ᵐ⁾| sᵢ⁽ᵐ⁾, logσᵢ⁽ᵐ⁾, sₜ)\n\nlogγₜ⁽ᵐ⁾ ~ Normal(μ = sᵢ⁽ᵐ⁾ - sₜ, σ = exp(logσᵢ⁽ᵐ⁾))\n\nArguments\n\nR̲̲::Vector{Matrix{Int64}}:: Length R vector wth T × B matrices where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each matrix in the vector, each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Vector{Vector{Int64}}: Vector of vectors with the total number of barcode counts for each time point on each replicate. NOTE: This vector must be equivalent to computing vec.(sum.(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset.  \nn_bc::Int: Number of mutant lineages in dataset.\n\nKeyword Arguments\n\ngenotypes::Vector{Vector{<:Any}}: Vector with the list of genotypes for each non-neutral barcode. \n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points in dataset.  \nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: logσ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points × number of replicates in dataset.\ns_bc_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_bc_prior[1] = mean, s_bc_prior[2] = standard deviation, Matrix: s_bc_prior[:, 1] = mean, s_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_bc_prior) <: Matrix, there should be as many rows in the matrix as number of mutant lineages × number of replicates in the dataset. \nlogσ_bc_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_bc_prior[1] = mean, logσ_bc_prior[2] = standard deviation, Matrix: logσ_bc_prior[:, 1] = mean, logσ_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(logσ_bc_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(logλ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint.\nGenotype hyper-fitness effects. \nNon-centered samples for each of the non-neutral barcodes.\nDeviations from the hyper parameter value for each non-neutral barcode.\nλ dispersion parameters per barcode and timepoint.\n\nNotes\n\nModels hyper-fitness effects as normally distributed.\nModels fitness effects as normally distributed.\nUtilizes a Poisson observation model for barcode counts.  \nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\n","category":"function"},{"location":"model/#Multi-replicate-single-environment-hierarchical-model-for-experimental-replicates","page":"model","title":"Multi-replicate single-environment hierarchical model for experimental replicates","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"BarBay.model.replicate_fitness_normal","category":"page"},{"location":"model/#BarBay.model.replicate_fitness_normal","page":"model","title":"BarBay.model.replicate_fitness_normal","text":"replicate_fitness_normal(R̲̲::Array{Int64,3}, n̲ₜ::Matrix{Int64},                       n_neutral::Int, n_bc::Int; kwargs...)\n\nDefines a hierarchical model to estimate fitness effects in a competitive fitness experiment across growth-dilution cycles over multiple experimental replicates. \n\nModel summary\n\nPrior on population mean fitness at time t in replicate r, π(sₜᵣ)\n\nsₜᵣ ~ Normal(params=s_pop_prior)\n\nPrior on population log mean fitness associated error at time t in replicate r, π(logσₜ)\n\nlogσₜᵣ ~ Normal(params=logσ_pop_prior)\n\nPrior on non-neutral relative hyper-fitness for barcode m π(θ⁽ᵐ⁾)\n\nθ⁽ᵐ⁾ ~ Normal(params=s_bc_prior)\n\nPrior on non-centered samples that allow local fitness to vary in the positive and negative direction for barcode m in experimental replicate r π(θ̃ᵣ⁽ᵐ⁾). Note, this is a standard normal with mean zero and standard deviation one. \n\nθ̃ᵣ⁽ᵐ⁾ ~ Normal(μ = 0, σ = 1)\n\nPrior on log deviations of local fitness from hyper-fitness for barcode m in replicate r π(logτᵣ⁽ᵐ⁾)\n\nlogτᵣ⁽ᵐ⁾ ~ Normal(params=logτ_prior)\n\nLocal relative fitness for non-neutral barcode m in replicate r (deterministic relationship from hyper-priors)\n\nsᵣ⁽ᵐ⁾ = θ⁽ᵐ⁾ + θ̃ᵣ⁽ᵐ⁾ * exp(logτᵣ⁽ᵐ⁾)\n\nPrior on non-neutral log relative fitness associated error for non-neutral barcode m in replcate r, π(logσᵣ⁽ᵐ⁾)\n\nlogσᵣ⁽ᵐ⁾ ~ Normal(params=logσ_bc_prior)\n\nPrior on log Poisson distribtion parameters for barcode m at time t in replicate r, π(logλₜᵣ⁽ᵐ⁾) \n\nlogλₜᵣ⁽ᵐ⁾ ~ Normal(params=logλ_prior)\n\nProbability of total number of barcodes read given the Poisson distribution parameters at time t in replicate r π(nₜᵣ | logλ̲ₜᵣ)\n\nnₜᵣ ~ Poisson(∑ₘ exp(λₜᵣ⁽ᵐ⁾))\n\nBarcode j frequency at time t in replciate r (deterministic relationship from the Poisson parameters)\n\nfₜᵣ⁽ʲ⁾ = λₜᵣ⁽ʲ⁾ / ∑ₖ λₜᵣ⁽ᵏ⁾\n\nLog frequency ratio for barcode j at time t in replicate r (deterministic relationship from barcode frequencies)\n\nlogγₜᵣ⁽ʲ⁾ = log(f₍ₜ₊₁₎ᵣ⁽ʲ⁾ / fₜᵣ⁽ʲ⁾)\n\nProbability of number of reads at time t for all barcodes in replicate r given the total number of reads and the barcode frequencies π(r̲ₜᵣ | nₜᵣ, f̲ₜᵣ)\n\nr̲ₜᵣ ~ Multinomial(nₜᵣ, f̲ₜᵣ)\n\nProbability of neutral barcodes n frequency ratio at time t in replicate r, π(logγₜᵣ⁽ⁿ⁾| sₜᵣ, logσₜᵣ)\n\nlogγₜᵣ⁽ⁿ⁾ ~ Normal(μ = -sₜᵣ, σ = exp(logσₜᵣ))\n\nProbability of non-neutral barcode m frequency ratio at time t in replicate r  π(logγₜᵣ⁽ᵐ⁾| sᵣ⁽ᵐ⁾, logσᵣ⁽ᵐ⁾, sₜᵣ)\n\nlogγₜ⁽ᵐ⁾ ~ Normal(μ = sᵣ⁽ᵐ⁾ - sₜᵣ, σ = exp(logσᵣ⁽ᵐ⁾))\n\nArguments\n\nR̲̲::Array{Int64, 3}:: T × B × R where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each slice in the R axis, each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Matrix{Int64}: Matrix with the total number of barcode counts for each time point on each replicate. NOTE: This matrix must be equivalent to computing vec(sum(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset.  \nn_bc::Int: Number of mutant lineages in dataset.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points in dataset.  \nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: logσ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points × number of replicates in dataset.\ns_bc_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_bc_prior[1] = mean, s_bc_prior[2] = standard deviation, Matrix: s_bc_prior[:, 1] = mean, s_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_bc_prior) <: Matrix, there should be as many rows in the matrix as number of mutant lineages × number of replicates in the dataset. \nlogσ_bc_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: s_bc_prior[1] = mean, s_bc_prior[2] = standard deviation, Matrix: s_bc_prior[:, 1] = mean, s_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(logσ_bc_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(logλ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint.\nMutant hyper-fitness effects. \nMutant fitness effects per experimental replicate.\nλ dispersion parameters per barcode and timepoint.\n\nNotes\n\nModels hyper-fitness effects as normally distributed.\nModels fitness effects as normally distributed.\nUtilizes a Poisson observation model for barcode counts.  \nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\nreplicatefitnessnormal(R̲̲::Vector{Matrix{Int64}}, n̲ₜ::Vector{Vector{Int64}},                       nneutral::Int, nbc::Int; kwargs...)\n\nDefines a hierarchical model to estimate fitness effects in a competitive fitness experiment across growth-dilution cycles over multiple experimental replicates. \n\nArguments\n\nR̲̲::Vector{Matrix{Int64}}:: Length R vector wth T × B matrices where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each matrix in the vector, each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Vector{Vector{Int64}}: Vector of vectors with the total number of barcode counts for each time point on each replicate. NOTE: This vector must be equivalent to computing vec.(sum.(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset.  \nn_bc::Int: Number of mutant lineages in dataset.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points in dataset.  \nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: logσ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points × number of replicates in dataset.\ns_bc_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_bc_prior[1] = mean, s_bc_prior[2] = standard deviation, Matrix: s_bc_prior[:, 1] = mean, s_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_bc_prior) <: Matrix, there should be as many rows in the matrix as number of mutant lineages × number of replicates in the dataset. \nlogσ_bc_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: s_bc_prior[1] = mean, s_bc_prior[2] = standard deviation, Matrix: s_bc_prior[:, 1] = mean, s_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(logσ_bc_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(logλ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint.\nMutant hyper-fitness effects. \nMutant fitness effects per experimental replicate.\nλ dispersion parameters per barcode and timepoint.\n\nNotes\n\nModels hyper-fitness effects as normally distributed.\nModels fitness effects as normally distributed.\nUtilizes a Poisson observation model for barcode counts.  \nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\n","category":"function"},{"location":"model/#Multi-replicate-multi-environment-hierarchical-model-for-experimental-replicates","page":"model","title":"Multi-replicate multi-environment hierarchical model for experimental replicates","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"BarBay.model.multienv_replicate_fitness_normal","category":"page"},{"location":"model/#BarBay.model.multienv_replicate_fitness_normal","page":"model","title":"BarBay.model.multienv_replicate_fitness_normal","text":"multienv_replicate_fitness_normal(R̲̲::Matrix{Int64}, n̲ₜ::Vector{Int64},                                n_neutral::Int, n_bc::Int; kwargs...)\n\nDefines a hierarchical model to estimate fitness effects in a competitive fitness experiment with different environments across growth-dilution cycles over multiple experimental replicates. \n\nModel summary\n\nPrior on population mean fitness at time t in replicate r, π(sₜᵣ)\n\nsₜᵣ ~ Normal(params=s_pop_prior)\n\nPrior on population log mean fitness associated error at time t in replicate r, π(logσₜ)\n\nlogσₜᵣ ~ Normal(params=logσ_pop_prior)\n\nPrior on non-neutral relative hyper-fitness for barcode m in environment i π(θᵢ⁽ᵐ⁾)\n\nθᵢ⁽ᵐ⁾ ~ Normal(params=s_bc_prior)\n\nPrior on non-centered samples that allow local fitness to vary in the positive and negative direction for barcode m in experimental replicate r in environment i π(θ̃ᵣᵢ⁽ᵐ⁾). Note, this is a standard normal with mean zero and standard deviation one. \n\nθ̃ᵣᵢ⁽ᵐ⁾ ~ Normal(μ = 0, σ = 1)\n\nPrior on log deviations of local fitness from hyper-fitness for barcode m in replicate r in environment i π(logτᵣᵢ⁽ᵐ⁾)\n\nlogτᵣᵢ⁽ᵐ⁾ ~ Normal(params=logτ_prior)\n\nLocal relative fitness for non-neutral barcode m in replicate r in environment i (deterministic relationship from hyper-priors)\n\nsᵣᵢ⁽ᵐ⁾ = θᵢ⁽ᵐ⁾ + θ̃ᵣᵢ⁽ᵐ⁾ * exp(logτᵣᵢ⁽ᵐ⁾)\n\nPrior on non-neutral log relative fitness associated error for non-neutral barcode m in replcate r in environment i, π(logσᵣᵢ⁽ᵐ⁾)\n\nlogσᵣᵢ⁽ᵐ⁾ ~ Normal(params=logσ_bc_prior)\n\nPrior on log Poisson distribtion parameters for barcode m at time t in replicate r, π(logλₜᵣ⁽ᵐ⁾) \n\nlogλₜᵣ⁽ᵐ⁾ ~ Normal(params=logλ_prior)\n\nProbability of total number of barcodes read given the Poisson distribution parameters at time t in replicate r π(nₜᵣ | logλ̲ₜᵣ)\n\nnₜᵣ ~ Poisson(∑ₘ exp(λₜᵣ⁽ᵐ⁾))\n\nBarcode j frequency at time t in replicate r (deterministic relationship from the Poisson parameters)\n\nfₜᵣ⁽ʲ⁾ = λₜᵣ⁽ʲ⁾ / ∑ₖ λₜᵣ⁽ᵏ⁾\n\nLog frequency ratio for barcode j at time t in replicate r (deterministic relationship from barcode frequencies)\n\nlogγₜᵣ⁽ʲ⁾ = log(f₍ₜ₊₁₎ᵣ⁽ʲ⁾ / fₜᵣ⁽ʲ⁾)\n\nProbability of number of reads at time t for all barcodes in replicate r given the total number of reads and the barcode frequencies π(r̲ₜᵣ | nₜᵣ, f̲ₜᵣ)\n\nr̲ₜᵣ ~ Multinomial(nₜᵣ, f̲ₜᵣ)\n\nProbability of neutral barcodes n frequency ratio at time t in replicate r, π(logγₜᵣ⁽ⁿ⁾| sₜᵣ, logσₜᵣ)\n\nlogγₜᵣ⁽ⁿ⁾ ~ Normal(μ = -sₜᵣ, σ = exp(logσₜᵣ))\n\nProbability of non-neutral barcodes frequency ratio for barcode m in replicate r π(logγₜᵣ⁽ᵐ⁾| sᵣ⁽ᵐ⁾, logσᵣ⁽ᵐ⁾, sₜᵣ). Note: This is done grouping by corresponding environment such that if time t is associated with environment i, sᵣᵢ⁽ᵐ⁾ is used as the fitness value.\n\nlogγₜᵣ⁽ᵐ⁾ ~ Normal(μ = sᵣᵢ⁽ᵐ⁾ - sₜᵣ, σ = exp(logσᵣᵢ⁽ᵐ⁾))\n\nArguments\n\nR̲̲::Array{Int64, 3}:: T × B × R where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each slice in the R axis, each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Matrix{Int64}: Matrix with the total number of barcode counts for each time point on each replicate. NOTE: This matrix must be equivalent to computing vec(sum(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset.  \nn_bc::Int: Number of mutant lineages in dataset.\n\nKeyword Arguments\n\nenvs::Vector{<:Any}: List of environments for each time point in dataset. NOTE: The length must be equal to that of the number of rows in n̲t to have one environment per time point.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points in dataset.  \nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: logσ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points × number of replicates in dataset.\ns_bc_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_bc_prior[1] = mean, s_bc_prior[2] = standard deviation, Matrix: s_bc_prior[:, 1] = mean, s_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_bc_prior) <: Matrix, there should be as many rows in the matrix as number of mutant lineages × number of replicates in the dataset. \nlogσ_bc_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_bc_prior[1] = mean, logσ_bc_prior[2] = standard deviation, Matrix: logσ_bc_prior[:, 1] = mean, logσ_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(logσ_bc_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(logλ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint.\nMutant hyper-fitness effects per environment. \nNon-centered samples for each of the experimental replicates.\nDeviations from the hyper parameter value for each experimental replicate.\nλ dispersion parameters per barcode and timepoint.\n\nNotes\n\nAll barcodes must be included in all replicates.\nModels hyper-fitness effects as normally distributed.\nModels fitness effects as normally distributed.\nUtilizes a Poisson observation model for barcode counts.  \nCan estimate time-varying and environment-specific fitness effects.\nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\nmultienvreplicatefitnessnormal(R̲̲::Vector{Matrix{Int64}},                                n̲ₜ::Vector{Vector{Int64}}, nneutral::Int,                                n_bc::Int; kwargs...)\n\nDefines a hierarchical model to estimate fitness effects in a competitive fitness experiment with different environments across growth-dilution cycles over multiple experimental replicates. \n\nArguments\n\nR̲̲::Vector{Matrix{Int64}}:: Length R vector wth T × B matrices where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each matrix in the vector, each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Vector{Vector{Int64}}: Vector of vectors with the total number of barcode counts for each time point on each replicate. NOTE: This vector must be equivalent to computing vec.(sum.(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset.  \nn_bc::Int: Number of mutant lineages in dataset.\n\nKeyword Arguments\n\nenvs::Vector{Vector{<:Any}}: Length R vector with the list of environments for each time point in each replicate. NOTE: The length must be equal to that of the number of rows in n̲ₜ to have one environment per time point.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points in dataset.  \nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: logσ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points × number of replicates in dataset.\ns_bc_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_bc_prior[1] = mean, s_bc_prior[2] = standard deviation, Matrix: s_bc_prior[:, 1] = mean, s_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_bc_prior) <: Matrix, there should be as many rows in the matrix as number of mutant lineages × number of replicates in the dataset. \nlogσ_bc_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_bc_prior[1] = mean, logσ_bc_prior[2] = standard deviation, Matrix: logσ_bc_prior[:, 1] = mean, logσ_bc_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(logσ_bc_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(logλ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint.\nMutant hyper-fitness effects per environment. \nNon-centered samples for each of the experimental replicates.\nDeviations from the hyper parameter value for each experimental replicate.\nλ dispersion parameters per barcode and timepoint.\n\nNotes\n\nAll barcodes must be included in all replicates.\nAll environments must appear at least once on each replicate.\nModels hyper-fitness effects as normally distributed.\nModels fitness effects as normally distributed.\nUtilizes a Poisson observation model for barcode counts.  \nCan estimate time-varying and environment-specific fitness effects.\nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\n","category":"function"},{"location":"stats/#stats","page":"stats","title":"stats","text":"","category":"section"},{"location":"stats/","page":"stats","title":"stats","text":"The stats module includes useful functions to compute statistical characterizations of the data and the output results.","category":"page"},{"location":"stats/#Posterior-Predictive-Checks","page":"stats","title":"Posterior Predictive Checks","text":"","category":"section"},{"location":"stats/","page":"stats","title":"stats","text":"BarBay.stats.logfreq_ratio_popmean_ppc","category":"page"},{"location":"stats/#BarBay.stats.logfreq_ratio_popmean_ppc","page":"stats","title":"BarBay.stats.logfreq_ratio_popmean_ppc","text":"logfreq_ratio_popmean_ppc(df, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. \n\nModel\n\nThe functional form that connects the barcode frequency at tie t+1 based on the frequency at time t for neutral barcodes is of the form\n\n    f_t+1^(n) = f_t^(n) \n    expleft left( - bars_t right) tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(n)f_t^(n) sim \n    log-mathcalNleft( - bars_t sigma^(n) right)\n\nwhere sigma^(n) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations       estimates for the likelihood.\n\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ)= s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\nlogfreq_ratio_popmean_ppc(chain, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. \n\nModel\n\nThe functional form that connects the barcode frequency at tie t+1 based on the frequency at time t for neutral barcodes is of the form\n\n    f_t+1^(n) = f_t^(n) \n    expleft left( - bars_t right) tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(n)f_t^(n) sim \n    log-mathcalNleft( - bars_t sigma^(n) right)\n\nwhere sigma^(n) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations         estimates for the likelihood.\n\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if the model used a normal or lognormal distribution for the likelihood. This is because when using a normal distribution, the nuisance parameters are sampled in log scale and need to be exponentiated.\nflatten::Bool=true: Boolean indicating whether to flatten the output of   multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"function"},{"location":"stats/","page":"stats","title":"stats","text":"BarBay.stats.logfreq_ratio_bc_ppc","category":"page"},{"location":"stats/#BarBay.stats.logfreq_ratio_bc_ppc","page":"stats","title":"BarBay.stats.logfreq_ratio_bc_ppc","text":"logfreq_ratio_bc_ppc(df, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. \n\nModel\n\nThe functional form that connects the barcode frequency at time t+1 with the frequency at time t is of the form\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. The statistical models in this package assume that\n\n    logleft(fracf_t+1^(m)f_t^(m)right) sim \n    mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution to produce the posterior predictive checks.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Keyword Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:\n\n:bc_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:bc_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of\n\nmultiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\nlogfreq_ratio_bc_ppc(chain, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. \n\nModel\n\nThe functional form that connects the barcode frequency at time t+1 with the frequency at time t is of the form\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. The statistical models in this package assume that\n\n    logleft(fracf_t+1^(m)f_t^(m)right) sim \n    mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution to produce the posterior predictive checks.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:\n\n:bc_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:bc_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of\n\nmultiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"function"},{"location":"stats/","page":"stats","title":"stats","text":"BarBay.stats.logfreq_ratio_multienv_ppc","category":"page"},{"location":"stats/#BarBay.stats.logfreq_ratio_multienv_ppc","page":"stats","title":"BarBay.stats.logfreq_ratio_multienv_ppc","text":"logfreq_ratio_mutienv_ppc(df, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. \n\nModel\n\nThe functional form that connects the barcode frequency at time t+1 with the frequency at time t is of the form\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. The statistical models in this package assume that\n\n    logleft(fracf_t+1^(m)f_t^(m)right) sim \n    mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution to produce the posterior predictive checks.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\nenvs::Vector{<:Any}: List of environments in experiment. This is used to index the corresponding fitness from the chain. NOTE: The list of environments should be the name or corresponding label of the environemnt; the index is generated internally.\n\nOptional Keyword Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:\n\n:bc_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:bc_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of\n\nmultiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\nlogfreqratiomutienvppc(chain, nppc; kwargs)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. \n\nModel\n\nThe functional form that connects the barcode frequency at time t+1 with the frequency at time t is of the form\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. The statistical models in this package assume that\n\n    logleft(fracf_t+1^(m)f_t^(m)right) sim \n    mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution to produce the posterior predictive checks.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations         estimates for the likelihood.\n\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if the model used a normal or lognormal distribution for the likelihood. This is because when using a normal distribution, the nuisance parameters are sampled in log scale and need to be exponentiated.\nflatten::Bool=true: Boolean indicating whether to flatten the output of   multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"function"},{"location":"stats/","page":"stats","title":"stats","text":"BarBay.stats.freq_bc_ppc","category":"page"},{"location":"stats/#BarBay.stats.freq_bc_ppc","page":"stats","title":"BarBay.stats.freq_bc_ppc","text":"freq_bc_ppc(df, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. \n\nModel\n\nThe functional form that connects the barcode frequency at time t+1 with the frequency at time t is of the form\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. The statistical models in this package assume that\n\n    logleft(fracf_t+1^(m)f_t^(m)right) sim \n    mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution to produce the posterior predictive checks.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables in the mcmc chain defining the following variables:\n:bc_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:bc_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\nbc_freq: Variable defining the inferred initial frequency for the mutant.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if   the model used a normal or lognormal distribution for the likelihood. This   is because when using a normal distribution, the nuisance parameters are   sampled in log scale and need to be exponentiated.\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\nfreq_bc_ppc(chain, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. \n\nModel\n\nThe functional form that connects the barcode frequency at time t+1 with the frequency at time t is of the form\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. The statistical models in this package assume that\n\n    logleft(fracf_t+1^(m)f_t^(m)right) sim \n    mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution to produce the posterior predictive checks.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables in the mcmc chain defining the following variables:\n:bc_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:bc_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\nbc_freq: Variable defining the inferred initial frequency for the mutant.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"function"},{"location":"stats/#Naive-estimates","page":"stats","title":"Naive estimates","text":"","category":"section"},{"location":"stats/","page":"stats","title":"stats","text":"BarBay.stats.naive_prior","category":"page"},{"location":"stats/#BarBay.stats.naive_prior","page":"stats","title":"BarBay.stats.naive_prior","text":"naive_prior(data; kwargs)\n\nFunction to compute a naive set of parameters for the prior distributions of the population mean fitness s̲ₜ values, the nuisance parameters in the log-likelihood functions for the frequency ratios logσ̲ₜ, and the log of the Poisson parameters for the observation model logΛ̲̲\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode   sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage\n\nor not.\n\nrep_col: (Optional) For hierarchical models to be build with multiple experimental replicates, this column defines which observations belong to which replicate.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point   at which measurements were done. The column may contain any type of entry as   long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing raw counts   per barcode. The column must contain entries of type <: Int.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether   the barcode belongs to a neutral lineage or not. The column must contain   entries of type Bool.\nrep_col::Union{Nothing,Symbol}=nothing: (Optional) Column indicating the experimental replicates each point belongs to.\npseudocount::Int=1: Pseudo counts to add to raw counts to avoid dividing by zero. This is useful if some of the barcodes go extinct.\nrm_T0::Bool=false: Optional argument to remove the first time point from the\n\ninference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\n\nReturns\n\nprior_params::Dict: Dictionary with two entries:\ns_pop_prior: Mean value of the population mean fitness. NOTE: This naive empirical method cannot make statements about the expected standard deviation of the population mean fitness. It is up to the researcher to determine this value.\nlogσ_pop_prior: Mean value on the nuisance parameter for the log-likelihood functions on the log-frequency ratios. In other words, the mean for the (log)-Normal distribution on the frequency ratios. NOTE: This naive empirical method cannot make statements about the expected standard deviation of the population mean fitness. It is up to the researcher to determine this value. NOTE: Typically, one can use the same estimate for both the neutral and the mutant lineages.\nlogλ_prior: Mean value of the nuisance parameter for the Poisson observation model parameter. NOTE: This naive empirical method cannot make statements about the expected standard deviation of the population mean fitness. It is up to the researcher to determine this value.\n\n\n\n\n\n","category":"function"},{"location":"stats/","page":"stats","title":"stats","text":"BarBay.stats.naive_fitness","category":"page"},{"location":"stats/#BarBay.stats.naive_fitness","page":"stats","title":"BarBay.stats.naive_fitness","text":"naive_fitness(data; id_col, time_col, count_col, neutral_col, pseudocount)\n\nFunction to compute a naive estimate of mutant fitness data based on counts. The fitness estimate is computed as\n\nleftlangle\nlogfracf^(m)_t+1f^(m)_t - logfracf^(n)_t+1f^(n)_t\nrightrangle = s^(m)\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to infer the fitness values on mutants. The DataFrame must contain at least the following columns:     - id_col: Column identifying the ID of the barcode. This can the barcode     sequence, for example.     - time_col: Column defining the measurement time point.     - count_col: Column with the raw barcode count.     - neutral_col: Column indicating whether the barcode is from a neutral     lineage or not.\n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the\n\ninference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\n\npseudocount::Int=1: Pseudo count number to add to all counts. This is useful to avoid divisions by zero.\n\nReturns\n\nDataFrames.DataFrame: Data frame with two columns:\nid_col: Column indicating the strain ID.\nfitness: Naive fitness estimate.\n\n\n\n\n\n","category":"function"},{"location":"stats/#Miscellaneous-statistical-functions","page":"stats","title":"Miscellaneous statistical functions","text":"","category":"section"},{"location":"stats/","page":"stats","title":"stats","text":"BarBay.stats.build_getq","category":"page"},{"location":"stats/#BarBay.stats.build_getq","page":"stats","title":"BarBay.stats.build_getq","text":"Function to build a full-rank distribution to be used for ADVI optimization. The code in this function comes from (Turing.jl tutorial)[https://turinglang.org/v0.28/tutorials/09-variational-inference/]\n\nArguments\n\ndim::Int: Dimensionality of parameter space.\nmodel::DynamicPPL.model: Turing model to be fit using ADVI.\n\nReturns\n\nInitialized distribution to be used when fitting a full-rank variational model.\n\n\n\n\n\n","category":"function"},{"location":"stats/","page":"stats","title":"stats","text":"BarBay.stats.matrix_quantile_range","category":"page"},{"location":"stats/#BarBay.stats.matrix_quantile_range","page":"stats","title":"BarBay.stats.matrix_quantile_range","text":"matrixquantilerange(quantile, matrix; dim=2) \n\nFunction to compute the quantile ranges of matrix matrix over dimension dim.\n\nFor example, if quantile[1] = 0.95, this function returns the 0.025 and  0.975 quantiles that capture 95 percent of the entries in the matrix.\n\nArguments\n\nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the posterior predictive checks.  \nmatrix::Matrix{<:Real}: Array over which to compute quantile ranges.\n\nKeyword Arguments\n\ndim::Int=2: Dimension over which to compute quantiles. Default is 2, i.e.  columns.\n\nReturns\n\nqs: Matrix with requested quantiles over specified dimension.\n\n\n\n\n\n","category":"function"},{"location":"math/#math","page":"math","title":"math","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"In this section we specify the core of the mathematical and statistical model behind the package. We invite the user to read the accompanying paper if some questions remain after reading this section.","category":"page"},{"location":"math/#Preliminaries-on-mathematical-notation","page":"math","title":"Preliminaries on mathematical notation","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"Before jumping directly into the Bayesian inference pipeline, let us establish the mathematical notation used throughout this paper. We define (column) vectors as underlined lowercase symbols such as","category":"page"},{"location":"math/","page":"math","title":"math","text":"underlinex = beginbmatrix\n    x_1\n    x_2\n    vdots\n    x_N\nendbmatrix\ntag1","category":"page"},{"location":"math/","page":"math","title":"math","text":"In the same way, we define matrices as double-underline uppercase symbols such as","category":"page"},{"location":"math/","page":"math","title":"math","text":"underlineunderlineA =\nbeginbmatrix\n    A_11  A_12  cdots  A_1N\n    A_21  A_22  cdots  A_2N\n    vdots  vdots  ddots  vdots\n    A_M1  A_M2  cdots  A_MN\nendbmatrix\ntag2","category":"page"},{"location":"math/","page":"math","title":"math","text":"math","category":"page"},{"location":"math/#Fitness-model","page":"math","title":"Fitness model","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"Empirically, the barcode relative frequency trajectories follow an exponential function of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_t+1^(b) = f_t^(b) mathrme^(s^(b) - bars_t)tau\ntag3","category":"page"},{"location":"math/","page":"math","title":"math","text":"where f_t^(b) is the frequency of barcode b at the end of cycle number t, s^(b) is the relative fitness with respect to the reference strain–-the quantity we want to infer from the data–-bars_t is the mean fitness of the culture at the end of cycle number t, and tau is the time pass between cycle t and t+1. We can rewrite Eq. 3 as","category":"page"},{"location":"math/","page":"math","title":"math","text":"frac1tauln fracf_t+1^(b)f_t^(b) = (s^(b) - bars_t)\ntag4","category":"page"},{"location":"math/","page":"math","title":"math","text":"Eq. 4 separates the measurements–-the barcode frequencies–-from the unobserved (sometimes referred to as latent) parameters we want to infer from the data–-the population mean fitness and the barcode relative fitness. This is ultimately the functional form used in our inference pipeline. Therefore, the relative fitness is computed by knowing the log frequency ratio of each barcode throughout the growth-dilution cycles.","category":"page"},{"location":"math/","page":"math","title":"math","text":"The presence of the neutral lineages facilitates the determination of the population mean fitness value bars_t. Since every relative fitness is determined relative to the neutral lineage that dominates the culture, we define their fitness to be s^(n) = 0, where the superscript (n) specifies their neutrality. This means that Eq. 4 for a neutral lineage takes the simpler form","category":"page"},{"location":"math/","page":"math","title":"math","text":"frac1tauln fracf_t+1^(n)f_t^(n) = - bars_t\ntag5","category":"page"},{"location":"math/","page":"math","title":"math","text":"Therefore, we can use the data from these reference barcodes to directly infer the value of the population mean fitness.","category":"page"},{"location":"math/","page":"math","title":"math","text":"It is important to notice that the frequencies f_t^(b) are not the allele frequencies in the population (most of the culture is not sequenced since the reference strain is not barcoded), but rather the relative frequencies in the total number of sequencing reads. A way to conceptualize this subtle but important point is to assume exponential growth in the number of cells N_t^(b) of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"N_t+1^(b) = N_t^(b) mathrme^lambda^(b)tau\ntag6","category":"page"},{"location":"math/","page":"math","title":"math","text":"for every barcode b with growth rate lambda^(b). However, when we sequence barcodes, we do not directly measure the number of cells, but some number of reads r_t^(b) that map to barcode b. In the simplest possible scenario, we assume","category":"page"},{"location":"math/","page":"math","title":"math","text":"r_t^(b) propto N_t^(b)\ntag7","category":"page"},{"location":"math/","page":"math","title":"math","text":"where, importantly, the proportionality constant depends on the total number of reads for the library for cycle t, which might vary from library to library. Therefore, to compare the number of reads between libraries at different time points, we must normalize the number of reads to the same scale. The simplest form is to define a relative abundance, i.e., a frequency with respect to the total number of reads,","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_t^(b) equiv fracr_t^(b)sum_b r_t^(b)\ntag8","category":"page"},{"location":"math/","page":"math","title":"math","text":"This is the frequency Eq. 3 describes.","category":"page"},{"location":"math/","page":"math","title":"math","text":"Our ultimate objective is to infer the relative fitness s^(m) for each of the M relevant barcodes in the experiment. To do so, we account for the three primary sources of uncertainty in our model:","category":"page"},{"location":"math/","page":"math","title":"math","text":"Uncertainty in the determination of frequencies. Our model relates frequencies","category":"page"},{"location":"math/","page":"math","title":"math","text":"between adjacent growth-dilution cycles to the fitness of the corresponding strain. However, we do not directly measure frequencies. Instead, our data for each barcode consists of a length T vector of counts underliner^(b) for each of the T cycles in which the measurements were taken.","category":"page"},{"location":"math/","page":"math","title":"math","text":"Uncertainty in the value of the population mean fitness. We define neutral","category":"page"},{"location":"math/","page":"math","title":"math","text":"lineages to have fitness s^(n) = 0, helping us anchor the value of the population mean fitness bars_t for each pair of adjacent growth cycles. Moreover, we take this parameter as an empirical parameter to be obtained from the data, meaning that we do not impose a functional form that relates bars_t to bars_t+1. Thus, we must infer the T-1 values of this population mean fitness with their uncertainty that must be propagated to the value of the mutants' relative fitness.","category":"page"},{"location":"math/","page":"math","title":"math","text":"Uncertainty in each of the mutants' fitness values. ","category":"page"},{"location":"math/","page":"math","title":"math","text":"To account for all these sources of uncertainty in a principled way, in the next section, we develop a Bayesian inference pipeline.","category":"page"},{"location":"math/#Bayesian-inference","page":"math","title":"Bayesian inference","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"Our ultimate objective is to infer the vector of relative fitness values","category":"page"},{"location":"math/","page":"math","title":"math","text":"underlines^M = (s^(1) s^(2) ldots s^(M))^dagger\ntag9","category":"page"},{"location":"math/","page":"math","title":"math","text":"where ^dagger indicates the transpose. Our data consists of an T times B matrix underlineunderlineR, where B = M + N is the number of unique barcodes given by the sum of the number of unique, relevant barcodes we care about, M, and the number of unique neutral barcodes, N, and T is the number of growth cycles where measurements were taken. The data matrix is then of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"underlineunderlineR = beginbmatrix\n-  underliner_1  - \n-  underliner_2  - \n  vdots  \n-  underliner_T  - \nendbmatrix\ntag10","category":"page"},{"location":"math/","page":"math","title":"math","text":"where each row underliner_t is a B-dimensional array containing the raw barcode counts at cycle t. We can further split each vector underliner_t into two vectors of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"underliner_t = beginbmatrix\nunderliner_t^N \nunderliner_t^M\nendbmatrix\ntag11","category":"page"},{"location":"math/","page":"math","title":"math","text":"i.e., the vector containing the neutral lineage barcode counts underliner_t^N and the corresponding vector containing the mutant barcode counts underliner_t^M. Following the same logic, matrix underlineunderlineR can be split into two matrices as","category":"page"},{"location":"math/","page":"math","title":"math","text":"underlineunderlineR = left \nunderlineunderlineR^N  underlineunderlineR^M\nright\ntag12","category":"page"},{"location":"math/","page":"math","title":"math","text":"where underlineunderlineR^N is a T times N matrix with the barcode reads time series for each neutral lineage and underlineunderlineR^M is the equivalent T times M matrix for the non-neutral lineages.","category":"page"},{"location":"math/","page":"math","title":"math","text":"Our objective is to compute the joint probability distribution for all relative fitness values given our data. We can express this joint posterior distribution using Bayes theorem as","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlines^M mid underlineunderlineR) = frac\npi(underlineunderlineR mid underlines^M) \npi(underlines^M)\npi(underlineunderlineR)\ntag13","category":"page"},{"location":"math/","page":"math","title":"math","text":"where hereafter pi(cdot) defines a probability density function, unless otherwise stated. When defining our statistical model, we need not to focus on the denominator on the right-hand side of Eq. 13. Thus, we can write","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlines^M mid underlineunderlineR) propto\npi(underlineunderlineR mid underlines^M) \npi(underlines^M)\ntag14","category":"page"},{"location":"math/","page":"math","title":"math","text":"However, when implementing the model computationally, the normalization constant on the right-hand side of Eq. 13 must be computed. This can be done from the definition of the model via an integral of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlineunderlineR) = int d^M underlines^M\npi(underlineunderlineR mid underlines^M) \npi(underlines^M)\ntag15","category":"page"},{"location":"math/","page":"math","title":"math","text":"also known as a marginalization integral. Hereafter, differentials of the form d^n imply a n-dimensional integral.","category":"page"},{"location":"math/","page":"math","title":"math","text":"Although Eq. 13 and Eq. 14 seem simple enough, recall that Eq. 3 relates barcode frequency values and the population mean fitness to the mutant relative fitness. Therefore, we must include these nuisance parameters as part of our inference problem. To include these nuisance parameters, let ","category":"page"},{"location":"math/","page":"math","title":"math","text":"underlinebars_T = (bars_1 bars_2 ldots bars_T-1)^dagger\ntag14","category":"page"},{"location":"math/","page":"math","title":"math","text":"be the vector containing the T-1 population mean fitness we compute from the T time points where measurements were taken. We have T-1 since the value of any bars_t requires cycle numbers t and t+1. Furthermore, let the matrix underlineunderlineF be a T times B matrix containing all frequency values. As with Eq. 12, we can split underlineunderlineF into two matrices of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"underlineunderlineF = left \nunderlineunderlineF^N  underlineunderlineF^M\nright\ntag15","category":"page"},{"location":"math/","page":"math","title":"math","text":"to separate the corresponding neutral and non-neutral barcode frequencies. With these nuisance variables in hand, the full inference problem we must solve takes the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(\n    underlines^M underlinebars_T underlineunderlineF mid\n    underlineunderlineR\n) propto\npi(\n    underlineunderlineR mid\n    underlines^M underlinebars_T underlineunderlineF\n)\npi(\n    underlines^M underlinebars_T underlineunderlineF\n)\ntag16","category":"page"},{"location":"math/","page":"math","title":"math","text":"To recover the marginal distribution over the non-neutral barcodes relative fitness values, we can numerically integrate out all nuisance parameters, i.e.,","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlines^M mid underlineunderlineR) =\nint d^T-1underlinebars_T\nint d^Bunderlinef_1 cdots\nint d^Bunderlinef_T\n\npi(\n    underlines^M underlinebars_T underlineunderlineF mid\n    underlineunderlineR\n)\ntag17","category":"page"},{"location":"math/#Factorizing-the-posterior-distribution","page":"math","title":"Factorizing the posterior distribution","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"The left-hand side of Eq. 16is extremely difficult to work with. However, we can take advantage of the structure of our inference problem to rewrite it in a more manageable form. Specifically, the statistical dependencies of our observations and latent variables allow us to factorize the joint distribution into the product of multiple conditional distributions. To gain some intuition about this factorization, let us focus on the inference of the population mean fitness values underlinebars_T. Eq. 4 relates the value of the population mean fitness to the neutral lineage frequencies and nothing else. This suggests that when writing the posterior for these population mean fitness parameters, we should be able to condition it only on the neutral lineage frequency values, i.e., pi(underlinebars_T mid underlineunderlineF^N). We point the reader to sec-bayes_def for the full mathematical details on this factorization. For our purpose here, it suffices to say we can rewrite the joint probability distribution as a product of conditional distributions of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(\n    underlines^M underlinebars_T underlineunderlineF mid\n    underlineunderlineR\n) =\npi(\n    underlines^M mid underlinebars_T underlineunderlineF^M\n)\npi(\n    underlinebars_T mid underlineunderlineF^N\n)\npi(underlineunderlineF mid underlineunderlineR)\ntag18","category":"page"},{"location":"math/","page":"math","title":"math","text":"Written in this form, Eq. 18 captures the three sources of uncertainty listed in sec-fitness_model in each term. Starting from right to left, the first term on the right-hand side of Eq. 18 accounts for the uncertainty when inferring the frequency values given the barcode reads. The second term accounts for the uncertainty in the values of the mean population fitness at different time points. The last term accounts for the uncertainty in the parameter we care about–-the mutants' relative fitnesses.","category":"page"},{"location":"math/","page":"math","title":"math","text":"In the next sections we will explicitly develop each of the terms in Eq. 18.","category":"page"},{"location":"math/#Frequency-uncertainty-\\pi(\\underline{\\underline{F}}-\\mid-\\underline{\\underline{R}})","page":"math","title":"Frequency uncertainty pi(underlineunderlineF mid underlineunderlineR)","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"We begin with the probability of the frequency values given the raw barcode reads. The first assumption is that the inference of the frequency values for time t is independent of any other time. Therefore, we can write the joint probability distribution as a product of independent distributions of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlineunderlineF mid underlineunderlineR) =\nprod_t=1^T pi(underlinef_t mid underliner_t)\ntag19","category":"page"},{"location":"math/","page":"math","title":"math","text":"where underlinef_t and underliner_t are the t-th row of the matrix containing all of the measurements for time t. We imagine that when the barcode reads are obtained via sequencing, the quantified number of reads is a Poisson sample from the \"true\" underlying number of barcodes within the pool. This translates to assuming that the number of reads for each barcode at any time point r^(b)_t is an independent Poisson random variable, i.e.,","category":"page"},{"location":"math/","page":"math","title":"math","text":"r^(b)_t sim operatornamePoiss(lambda^(b)_t)\ntag20","category":"page"},{"location":"math/","page":"math","title":"math","text":"where the symbol \"sim\" is read \"distributed as.\" Furthermore, for a Poisson distribution, we have that","category":"page"},{"location":"math/","page":"math","title":"math","text":"lambda^(b)_t = leftlangle r^(b)_t rightrangle = \nleftlangle \n    left( r^(b)_t - leftlangle r^(b)_t rightrangle right)^2\nrightrangle\ntag21","category":"page"},{"location":"math/","page":"math","title":"math","text":"where leftlangle cdot rightrangle is the expected value. In other words the Poisson parameter is equal to the mean and variance of the distribution. The Poisson distribution has the convenient property that for two Poisson distributed random variables X sim operatornamePoiss(lambda_x) and Y sim operatornamePoiss(lambda_y), we have that","category":"page"},{"location":"math/","page":"math","title":"math","text":"Z equiv X + Y sim operatornamePoiss(lambda_x + lambda_y)\ntag22","category":"page"},{"location":"math/","page":"math","title":"math","text":"This additivity allows us to write the total number of reads at time t n_t also as a Poisson-distributed random variable of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"n_t sim operatornamePoissleft( sum_b=1^B lambda^(b)_t right)\ntag23","category":"page"},{"location":"math/","page":"math","title":"math","text":"where the sum is taken over all B barcodes.","category":"page"},{"location":"math/","page":"math","title":"math","text":"If the total number of reads is given by Eq. 23, the array with the number of reads for each barcode at time t, underliner_t is then distributed as","category":"page"},{"location":"math/","page":"math","title":"math","text":"underliner_t sim operatornameMultinomial(n_t underlinef_t)\ntag24","category":"page"},{"location":"math/","page":"math","title":"math","text":"where each of the B entries of the frequency vector underlinef_t is a function of the underlinelambda_t vector, given by","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_t^(b) equiv f_t^(b)(underlinelambda_t) = \nfraclambda_t^(b)sum_b=1^B lambda_t^(b)\ntag25","category":"page"},{"location":"math/","page":"math","title":"math","text":"In other words, we can think of the B barcode counts as independent Poisson samples or as a single multinomial draw with a random number of total draws, n_t, and the frequency vector underlinef_t we are interested in. Notice that Eq. 25 is a deterministic function that connects the Poisson parameters to the frequencies. Therefore, we have the equivalence that","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlinef_t mid underliner_t) = \npi(underlinelambda_t mid underliner_t)\ntag26","category":"page"},{"location":"math/","page":"math","title":"math","text":"meaning that the uncertainty comes from the underlinelambda_t vector. By Bayes theorem, we therefore write","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlinelambda_t mid n_t underliner_t) propto\npi(n_t underliner_t mid underlinelambda_t) pi(underlinelambda_t)\ntag27","category":"page"},{"location":"math/","page":"math","title":"math","text":"where we explicitly include the dependence on n_t. This does not affect the distribution or brings more uncertainty because underliner_t already contains all the information to compute n_t since","category":"page"},{"location":"math/","page":"math","title":"math","text":"n_t = sum_b=1^B r_t^(b)\ntag28","category":"page"},{"location":"math/","page":"math","title":"math","text":"But adding the variable allows us to factorize Eq. 27 as","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlinelambda_t mid n_t underliner_t) propto\npi(underliner_t mid n_t underlinelambda_t)\npi(n_t mid underlinelambda_t)\npi(underlinelambda_t)\ntag29","category":"page"},{"location":"math/","page":"math","title":"math","text":"We then have","category":"page"},{"location":"math/","page":"math","title":"math","text":"underliner_t mid n_t underlinelambda_t sim\noperatornameMultinomial(n_t underlinef_t(underlinelambda_t))\ntag30","category":"page"},{"location":"math/","page":"math","title":"math","text":"Furthermore, we have","category":"page"},{"location":"math/","page":"math","title":"math","text":"n_t mid underlinelambda_t sim \noperatornamePoissleft(sum_b=1^B lambda_t^(b)right)\ntag31","category":"page"},{"location":"math/","page":"math","title":"math","text":"Finally, for our prior pi(underlinelambda_t), we first assume each  parameter is independent, i.e.,","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlinelambda_t) = prod_b=1^B pi(lambda_t^(b))\ntag32","category":"page"},{"location":"math/","page":"math","title":"math","text":"A reasonable prior for each lambda_t^(b) representing the expected number of reads for barcode b should span several orders of magnitude. Furthermore, we assume that no barcode in the dataset ever goes extinct. Thus, no frequency can equal zero, facilitating the computation of the log frequency ratios needed to infer the relative fitness. The log-normal distribution satisfies these constraints; therefore, for the prior, we assume","category":"page"},{"location":"math/","page":"math","title":"math","text":"lambda_t^(b) sim \nlogmathcalN(mu_lambda_t^(b) sigma_lambda_t^(b))\ntag33","category":"page"},{"location":"math/","page":"math","title":"math","text":"with mu_lambda_t^(b) sigma_lambda_t^(b) as the user-defined  parameters that characterize the prior distribution.","category":"page"},{"location":"math/#Summary","page":"math","title":"Summary","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"Putting all the pieces developed in this section together gives a term for our inference of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlineunderlineF mid underlineunderlineR) propto\nprod_t=1^Tleft\n    pi(underliner_t mid n_t underlinelambda_t)\n    pi(n_t mid underlinelambda_t)\n    left \n        prod_b=1^B pi(lambda_t^(b))\n    right\nright\ntag34","category":"page"},{"location":"math/","page":"math","title":"math","text":"where","category":"page"},{"location":"math/","page":"math","title":"math","text":"underliner_t mid n_t underlinelambda_t sim\noperatornameMultinomial(n_t underlinef_t(underlinelambda_t))\ntag35","category":"page"},{"location":"math/","page":"math","title":"math","text":"n_t mid underlinelambda_t sim \noperatornamePoissleft(sum_b=1^B lambda_t^(b)right)\ntag36","category":"page"},{"location":"math/","page":"math","title":"math","text":"and","category":"page"},{"location":"math/","page":"math","title":"math","text":"lambda_t^(b) sim \nlogmathcalN(mu_lambda_t^(b) sigma_lambda_t^(b))\ntag37","category":"page"},{"location":"math/#Population-mean-fitness-uncertainty-\\pi(\\underline{\\bar{s}}_T-\\mid-\\underline{\\underline{F}},-\\underline{\\underline{R}})","page":"math","title":"Population mean fitness uncertainty pi(underlinebars_T mid underlineunderlineF underlineunderlineR)","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"Next, we turn our attention to the problem of determining the population mean fitnesses underlinebars_T. First, we notice that our fitness model in eq-fitness does not include the value of the raw reads. They enter the calculation indirectly through the inference of the frequency values we developed in sec-bayesfreq. This means that we can remove the conditioning of the value of ``\\underline{\\bar{s}}T`` on the number of reads, obtaining a simpler probability function","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(\n    underlinebars_T mid \n    underlineunderlineF underlineunderlineR\n) = \npi(\n    underlinebars_T mid \n    underlineunderlineF\n)\ntag38","category":"page"},{"location":"math/","page":"math","title":"math","text":"Moreover, our fitness model does not directly explain how the population mean fitness evolves over time. In other words, our model cannot explicitly compute the population mean fitness at time t+1 from the information we have about time t. Given this model limitation, we are led to assume that we must infer each bars_t independently. Expressing this for our inference results in","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(\n    underlinebars_T mid \n    underlineunderlineF\n) =\nprod_t=1^T-1 pi(bars_t mid underlinef_t underlinef_t+1)\ntag39","category":"page"},{"location":"math/","page":"math","title":"math","text":"where we split our matrix underlineunderlineF for each time point and only kept the conditioning on the relevant frequencies needed to compute the mean fitness at time t.","category":"page"},{"location":"math/","page":"math","title":"math","text":"Although our fitness model in eq-fitness also includes the relative fitness s^(m), to infer the population mean fitness we only utilize data from the neutral lineages that, by definition, have a relative fitness s^(n) = 0. Therefore, the conditioning on Eq. 39can be further simplified by only keeping the frequencies of the neutral lineages, i.e.,","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(bars_t mid underlinef_t underlinef_t+1) =\npi(bars_t mid underlinef_t^N underlinef_t+1^N)\ntag40","category":"page"},{"location":"math/","page":"math","title":"math","text":"Earlier, we emphasized that the frequencies f_t^(n) do not represent the true frequency of a particular lineage in the population but rather a \"normalized number of cells.\" Therefore, it is safe to assume each of the N neutral lineages' frequencies is changing independently. The correlation of how increasing the frequency of one lineage will decrease the frequency of others is already captured in the model presented in sec-bayes_freq. Thus, we write","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(bars_t mid underlinef_t^N underlinef_t+1^N) =\nprod_n=1^N pi(bars_t mid f_t^(n) f_t+1^(n))\ntag41","category":"page"},{"location":"math/","page":"math","title":"math","text":"Now, we can focus on one of the terms on the right-hand side of Eq. 41. Writing Bayes theorem results in","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(bars_t mid f_t^(n) f_t+1^(n)) propto\npi(f_t^(n) f_t+1^(n) mid bars_t) pi(bars_t)\ntag42","category":"page"},{"location":"math/","page":"math","title":"math","text":"Notice the likelihood defines the joint distribution of neutral barcode frequencies conditioned on the population mean fitness. However, rewriting our fitness model in eq-fitness for a neutral lineage to leave frequencies on one side and fitness on the other results in","category":"page"},{"location":"math/","page":"math","title":"math","text":"fracf_t+1^(n)f_t^(n) = mathrme^- bars_ttau\ntag43","category":"page"},{"location":"math/","page":"math","title":"math","text":"Eq. 43 implies that our fitness model only relates the ratio of frequencies and not the individual values. To get around this complication, we define","category":"page"},{"location":"math/","page":"math","title":"math","text":"gamma_t^(b) equiv fracf_t+1^(b)f_t^(b)\ntag44","category":"page"},{"location":"math/","page":"math","title":"math","text":"as the ratio of frequencies between two adjacent time points for any barcode b. This allows us to rewrite the joint distribution pi(f_t^(n) f_t+1^(n) mid bars_t) as","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(f_t^(n) f_t+1^(n) mid bars_t) =\npi(f_t^(n) gamma_t^(n) mid bars_t)\ntag45","category":"page"},{"location":"math/","page":"math","title":"math","text":"Let us rephrase this subtle but necessary change of variables since it is a key part of the inference problem: our series of independence assumptions lead us to Eq. 42that relates the value of the population mean fitness bars_t to the frequency of a neutral barcode at times t and t+1. However, as shown in Eq. 43, our model functionally relates the ratio of frequencies–-that we defined as gamma_t^(n)–-and not the independent frequencies to the mean fitness. Therefore, instead of writing for the likelihood the joint distribution of the frequency values at times t and t+1 conditioned on the mean fitness, we write the joint distribution of the barcode frequency at time t and the ratio of the frequencies. These must be equivalent joint distributions since there is a one-to-one mapping between gamma_t^(n) and f_t+1^(n) for a given value of f_t^(n). Another way to phrase this is to say that knowing the frequency at time t and at time t+1 provides the same amount of information as knowing the frequency at time t and the ratio of the frequencies. This is because if we want to obtain f_t+1^(n) given this information, we simply compute","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_t+1^(n) = gamma_t^(n) f_t^(n)\ntag46","category":"page"},{"location":"math/","page":"math","title":"math","text":"The real advantage of rewriting the joint distribution as in Eq. 45 comes from splitting this joint distribution as a product of conditional distributions of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(f_t^(n) gamma_t^(n) mid bars_t) =\npi(f_t^(n) mid gamma_t^(n) bars_t)\npi(gamma_t^(n) mid bars_t)\ntag47","category":"page"},{"location":"math/","page":"math","title":"math","text":"Written in this form, we can finally propose a probabilistic model for how the mean fitness relates to the frequency ratios we determine in our experiments. The second term on the right-hand side of Eq. 47 relates how the determined frequency ratio gamma_t^(b) relates to the mean fitness bars_t. From Eq. 43 and Eq. 44, we can write","category":"page"},{"location":"math/","page":"math","title":"math","text":"ln gamma_t^(n) = - bars_t + varepsilon_t^(n)\ntag48","category":"page"},{"location":"math/","page":"math","title":"math","text":"where, for simplicity, we set tau = 1. Note that we added an extra term, varepsilon_t^(n), characterizing the deviations of the measurements from the theoretical model. We assume these errors are normally distributed with mean zero and some standard deviation sigma_t, implying that","category":"page"},{"location":"math/","page":"math","title":"math","text":"ln gamma_t^(n) mid bars_t sigma_t  sim \nmathcalNleft(-bars_t sigma_t right)\ntag49","category":"page"},{"location":"math/","page":"math","title":"math","text":"where we include the nuisance parameter sigma_t to be determined. If we assume the log frequency ratio is normally distributed, this implies the frequency ratio itself is distributed log-normal. This means that","category":"page"},{"location":"math/","page":"math","title":"math","text":"gamma_t^(n) mid bars_t sigma_t  sim \nlog mathcalNleft(-bars_t sigma_t right)\ntag50","category":"page"},{"location":"math/","page":"math","title":"math","text":"Having added the nuisance parameter sigma_t implies that we must update Eq. 42 to","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(bars_t sigma_t mid f_t^(n) f_t+1^(n)) propto\npi(f_t^(n) gamma_t^(n) mid bars_t sigma_t) \npi(bars_t) pi(sigma_t)\ntag51","category":"page"},{"location":"math/","page":"math","title":"math","text":"where we assume the prior for each parameter is independent, i.e.,","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(bars_t sigma_t) = pi(bars_t) pi(sigma_t)\ntag52","category":"page"},{"location":"math/","page":"math","title":"math","text":"For numerical stability, we will select weakly-informative priors for both of these parameters. In the case of the nuisance parameter sigma_t, the prior must be restricted to positive values only, since standard deviations cannot be negative.","category":"page"},{"location":"math/","page":"math","title":"math","text":"For the first term on the right-hand side of Eq. 47, pi(f_t^(n) mid gamma_t^(n) bars_t), we remove the conditioning on the population mean fitness since it does not add any information on top of what the frequency ratio gamma_t^(n) already gives. Therefore, we have","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(f_t^(n) mid gamma_t^(n) bars_t) =\npi(f_t^(n) mid gamma_t^(n))\ntag53","category":"page"},{"location":"math/","page":"math","title":"math","text":"The right-hand side of Eq. 53 asks us to compute the probability of observing a frequency value f_t^(n) given that we get to observe the ratio gamma_t^(n). If the ratio happened to be gamma_t^(n) = 2, we could have f_t+1^(n) = 1 and f_t+1^(n) = 05, for example. Although, it would be equally likely that f_t+1^(n) = 06 and f_t+1^(n) = 03 or f_t+1^(n) = 01 and f_t+1^(n) = 005 for that matter. If we only get to observe the frequency ratio gamma_t^(n), we know that the numerator f_t+1^(n) can only take values between zero and one, all of them being equally likely given only the information on the ratio. As a consequence, the value of the frequency in the denominator f_t^(n) is restricted to fall in the range","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_t^(n) in left(0 frac1gamma_t^(n) right\ntag54","category":"page"},{"location":"math/","page":"math","title":"math","text":"A priori, we do not have any reason to favor any value over any other, therefore it is natural to write","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_t^(n) mid gamma_t^(n) sim \noperatornameUniformleft( 0 frac1gamma_t^(n) right)\ntag55","category":"page"},{"location":"math/#Summary-2","page":"math","title":"Summary","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"Putting all the pieces we have developed in this section together results in an inference for the population mean fitness values of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(\n    underlinebars_T underlinesigma_T mid underlineunderlineF\n) propto\nprod_t=1^T-1 left\n    prod_n=1^N left\n        pi(f_t^(n) mid gamma_t^(n)) \n        pi(gamma_t^(n) mid bars_t sigma_t)\n    right\n    pi(bars_t) pi(sigma_t)\nright\ntag56","category":"page"},{"location":"math/","page":"math","title":"math","text":"where we have","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_t^(n) mid gamma_t^(n) sim \noperatornameUniform left(0 frac1gamma_t^(n) right)\ntag57","category":"page"},{"location":"math/","page":"math","title":"math","text":"gamma_t^(n) mid bars_t sigma_t sim \nlogmathcalN(bars_t sigma_t)\ntag58","category":"page"},{"location":"math/","page":"math","title":"math","text":"bars_t sim mathcalN(0 sigma_bars_t)\ntag59","category":"page"},{"location":"math/","page":"math","title":"math","text":"and","category":"page"},{"location":"math/","page":"math","title":"math","text":"sigma_t sim logmathcalN(mu_sigma_t sigma_sigma_t)\ntag60","category":"page"},{"location":"math/","page":"math","title":"math","text":"where sigma_bars_t, mu_sigma_t, and sigma_sigma_t are user-defined parameters.","category":"page"},{"location":"math/#Mutant-relative-fitness-uncertainty-\\pi(\\underline{s}M-\\mid-\\underline{\\bar{s}}_T,-\\underline{\\underline{F}},-\\underline{\\underline{R}})","page":"math","title":"Mutant relative fitness uncertainty pi(underlines^M mid underlinebars_T underlineunderlineF underlineunderlineR)","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"The last piece of our inference is the piece that we care about the most: the probability distribution of all the mutants' relative fitness, given the inferred population mean fitness and the frequencies. First, we assume that all fitness values are independent of each other. This allows us to write","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(\n    underlines^M mid \n    underlinebars_T underlineunderlineF underlineunderlineR\n) = \nprod_m=1^M pi(\n    s^(m) mid\n    underlinebars_T underlineunderlineF underlineunderlineR\n)\ntag61","category":"page"},{"location":"math/","page":"math","title":"math","text":"Furthermore, as was the case with the population mean fitness, our fitness model relates frequencies, not raw reads. Moreover, the fitness value of mutant m only depends on the frequencies of such mutant. Therefore, we can simplify the conditioning to","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(\n    s^(m) mid\n    underlinebars_T underlineunderlineF underlineunderlineR\n) = \npi(s^(m) mid underlinebars_T underlinef^(m))\ntag62","category":"page"},{"location":"math/","page":"math","title":"math","text":"where","category":"page"},{"location":"math/","page":"math","title":"math","text":"underlinef^(m) = (f_0^(m) f_1^(m) ldots f_T^(m))^dagger\ntag63","category":"page"},{"location":"math/","page":"math","title":"math","text":"is the vector containing the frequency time series for mutant m. Writing Bayes' theorem for the right-hand side of Eq. 62 results in","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(s^(m) mid underlinebars_T underlinef^(m)) propto\npi(underlinef^(m) mid underlinebars_T s^(m))\npi(s^(m) mid underlinebars_T)\ntag64","category":"page"},{"location":"math/","page":"math","title":"math","text":"Notice the conditioning on the mean fitness values underlinebars_T is not inverted since we already inferred these values.","category":"page"},{"location":"math/","page":"math","title":"math","text":"Following the logic used in sec-bayes_meanfit, let us define","category":"page"},{"location":"math/","page":"math","title":"math","text":"underlinegamma^(m) = \n(gamma_0^(m) gamma_1^(m) ldots gamma_T-1^m)^dagger\ntag65","category":"page"},{"location":"math/","page":"math","title":"math","text":"where each entry gamma_t^(m) is defined by eq-gammadef. In the same way we rewrote the joint distribution between two adjacent time point frequencies to the joint distribution between one of the frequencies and the ratio of both frequencies in eq-jointfreq_gamma, we can rewrite the joint distribution of the frequency time series for mutant m as","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(underlinef^(m) mid underlinebars_T s^(m)) =\npi(f_0^(m) underlinegamma^(m) mid underlinebars_T s^(m))\ntag66","category":"page"},{"location":"math/","page":"math","title":"math","text":"One can think about Eq. 66 as saying that knowing the individual frequencies at each time point contain equivalent information as knowing the initial frequency and the subsequent ratios of frequencies. This is because if we want to know the value of f_1^(m) given the ratios, we only need to compute","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_1^(m) = gamma_0^(m) f_0^(m)\ntag67","category":"page"},{"location":"math/","page":"math","title":"math","text":"Moreover, if we want to know f_2^(m), we have","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_2^(m) = gamma_1^(m) f_1^(m) =\ngamma_1^(m) left(gamma_0^(m) f_0^(m)right)\ntag68","category":"page"},{"location":"math/","page":"math","title":"math","text":"and so on. We can then write the joint distribution on the right-hand side of Eq. 66 as a product of conditional distributions of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"beginaligned\npi(f_0^(m) underlinegamma^(m) mid underlinebars_T s^(m)) =\npi(\n    f_0^(m) mid \n    gamma_0^(m) ldots gamma_T-1^(m) underlinebars_T s^(m)\n) times \npi(\n    gamma_0^(m) mid \n    gamma_1^(m) ldots gamma_T-1^(m) underlinebars_T s^(m)\n) times \npi(\n    gamma_1^(m) mid \n    gamma_2^(m) ldots gamma_T-1^(m) underlinebars_T s^(m)\n) times \nvdots \npi(\n    gamma_T-2^(m) mid gamma_T-1^(m) underlinebars_T s^(m)\n) times \npi(gamma_T-1^(m) mid underlinebars_T s^(m))\nendaligned\ntag69","category":"page"},{"location":"math/","page":"math","title":"math","text":"Writing the fitness model in eq-fitness as","category":"page"},{"location":"math/","page":"math","title":"math","text":"gamma_t^(m) = fracf_t+1^(m)f_t^(m) = \nmathrme^(s^(m) - s_t)tau\ntag70","category":"page"},{"location":"math/","page":"math","title":"math","text":"reveals that the value of each of the ratios gamma_t^(m) only depends on the corresponding fitness value bars_t and the relative fitness s^(m). Therefore, we can remove most of the conditioning on the right-hand side of Eq. 69 resulting in a much simpler joint distribution of the form","category":"page"},{"location":"math/","page":"math","title":"math","text":"beginaligned\npi(f_0^(m) underlinegamma^(m) mid underlinebars_T s^(m)) =\npi(f_0^(m) mid gamma_0^(m)) times \npi(gamma_0^(m) mid bars_0 s^(m)) times \npi(gamma_1^(m) mid bars_1 s^(m)) times \nvdots \npi(gamma_T-2^(m) mid bars_T-2 s^(m)) times \npi(gamma_T-1^(m) mid bars_T-1 s^(m))\nendaligned\ntag71","category":"page"},{"location":"math/","page":"math","title":"math","text":"where for the first term on the right-hand side of Eq. 71 we apply the same logic as in eq-freqcondgamma to remove all other dependencies. We emphasize that although Eq. 71 looks like a series of independent inferences, the value of the relative fitness s^(m) is shared among all of them. This means that the parameter is not inferred individually for each time point, resulting in different estimates of the parameter, but each time point contributes independently to the inference of a single estimate of s^(m).","category":"page"},{"location":"math/","page":"math","title":"math","text":"Using equivalent arguments to those in sec-bayes_meanfit, we assume","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_0^(m) mid gamma_0^(m) sim \noperatornameUniformleft(0 frac1gamma_0^(m) right)\ntag72","category":"page"},{"location":"math/","page":"math","title":"math","text":"and","category":"page"},{"location":"math/","page":"math","title":"math","text":"gamma_t^(m) mid bars_t s^(m) sigma^(m) sim \nlogmathcalNleft(s^(m) - bars_t sigma^(m) right)\ntag73","category":"page"},{"location":"math/","page":"math","title":"math","text":"where we add the nuisance parameter sigma^(m) to the inference. Notice that this parameter is not indexed by time. This means that we assume the deviations from the theoretical prediction do not depend on time, but only on the mutant. Adding the nuisance parameter demands us to update Eq. 64to","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(\n    s^(m) sigma^(m) mid underlinebars_T underlinef^(m)\n) propto\npi(underlinef^(m) mid underlinebars_T s^(m) sigma^(m))\npi(s^(m)) pi(sigma^(m))\ntag74","category":"page"},{"location":"math/","page":"math","title":"math","text":"where we assume independent priors for both parameters. We also removed the conditioning on the values of the mean fitness as knowing such values does not change our prior information about the possible range of values that the parameters can take. As with the priors on sec-bayes_meanfit, we will assign weakly-informative priors to these parameters.","category":"page"},{"location":"math/#Summary-3","page":"math","title":"Summary","text":"","category":"section"},{"location":"math/","page":"math","title":"math","text":"With all pieces in place, we write the full inference of the relative fitness values as","category":"page"},{"location":"math/","page":"math","title":"math","text":"pi(\n    underlines^M underlinesigma^M mid \n    underlinebars_T underlineunderlineF\n) propto\nprod_m=1^M left \n    pi(f_0^(m) mid gamma_0^(m))\n    prod_t=0^T-1 left\n        pi(gamma_t^(m) mid bars_t s^(m) sigma^(m))\n    right\n    pi(s^(m)) pi(sigma^(m))\nright\ntag75","category":"page"},{"location":"math/","page":"math","title":"math","text":"where","category":"page"},{"location":"math/","page":"math","title":"math","text":"f_0^(m) mid gamma_0^(m) sim \noperatornameUniformleft(0 frac1gamma_0^(m) right)\ntag76","category":"page"},{"location":"math/","page":"math","title":"math","text":"gamma_t^(m) mid bars_t s^(m) sigma^(m) sim \nlogmathcalNleft(s^(m) - bars_t sigma^(m) right)\ntag77","category":"page"},{"location":"math/","page":"math","title":"math","text":"s^(m) sim mathcalN(0 sigma_s^(m))\ntag78","category":"page"},{"location":"math/","page":"math","title":"math","text":"and","category":"page"},{"location":"math/","page":"math","title":"math","text":"sigma^(m) sim logmathcalN(mu_sigma^(m) sigma_sigma^(m))","category":"page"},{"location":"math/","page":"math","title":"math","text":"where sigma_s^(m), mu_sigma^(m), and sigma_sigma^(m) are user-defined parameters.","category":"page"},{"location":"#BarBay","page":"BarBay","title":"BarBay","text":"","category":"section"},{"location":"","page":"BarBay","title":"BarBay","text":"Welcome to the documentation of BarBay.jl! The accompanying paper, Bayesian inference of relative fitness on high-throughput pooled competition assays, explains all of the biological and mathematical background needed to understand this package. Here, we mainly focus on how to use the package, assuming the user already understands the objective of inferring the posterior probability distribution of the relative fitness of mutant strains in a pooled competition assay.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"The package is divided into modules. Here's a brief description of the content of each module, but please visit their respective documentations to understand what each module is intended for.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"utils: Series of miscellaneous functions that make the data wrangling and processing much simpler.\nstats: Statistical functions used in the inference problem.\nmodel: Turing.jl-based Bayesian models used to infer the population mean fitness via the neutral lineages as well as the mutants' relative fitness.\nvi: The main module with which to implement the automatic differentiation variational inference modality of the inference pipeline.\nmcmc: The module with which to perform the Markov-Chain Monte Carlo sampling of the posterior distributions.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"If you are interested in the mathematical details or want to get a quick  reminder, please check the math tab.","category":"page"},{"location":"#Contents","page":"BarBay","title":"Contents","text":"","category":"section"},{"location":"","page":"BarBay","title":"BarBay","text":"","category":"page"},{"location":"#Example-inference","page":"BarBay","title":"Example inference","text":"","category":"section"},{"location":"","page":"BarBay","title":"BarBay","text":"To get you going with the package, let's walk through a basic inference pipeline for one competition assay. Our ultimate goal consists of inferring the relative fitness for each of the barcoded genotypes of interest. To that end, we assume that the frequency time-series obeys the following equation","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"f_t+1^(b) = f_t^(b) mathrme^left(s^(b) - bars_t right)tau\ntag1","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"where f_t^(b) is the frequency of barcode b at the end of growth cyclet, s^(b) is the relative fitness of this barcode, bars_t is the population mean fitness at cycle t, and tau is the time interval between cycle t and t+1.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"The first step consists of importing the necessary packages. ","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"note: Note\nWe use import rather than the more common using command that most Julia tutorials and packages utilize. We find it better to keep the project organized, but feel free to use whatever is more convenient for you!","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Import Bayesian inference package\nimport BarBay\n\n# Import libraries to manipulate data\nimport DataFrames as DF\nimport CSV","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"After having imported the libraries, we need to load our dataset into memory.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"warning: Warning\nBarBay.jl requires the dataset to follow the so-called tidy format. Effectively, what this means is that each observation is stored as a single line in the table. So, instead of having all barcode counts for a particular time point across some row (or column), each barcode count for each time point gets its own line. See the example below to get a sense of what this tidy format implies.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Import data\ndata = CSV.read(\"/path/to/data/tidy_data.csv\", DF.DataFrame)","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"Here you will replace \"/path/to/data/\" with the directory where your data is stored, and \"tidy_data.csv\" with the name of the file containing the data. The resulting DataFrame looks something like this:","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"| time | barcode    | count | neutral | freq        |\n|------|------------|-------|---------|-------------|\n| 3    | neutral025 | 12478 | TRUE    | 0.000543716 |\n| 4    | neutral025 | 10252 | TRUE    | 0.00034368  |\n| 5    | neutral025 | 2883  | TRUE    | 6.74E-05    |\n| 1    | mut001     | 1044  | FALSE   | 7.97E-05    |\n| 2    | mut001     | 2010  | FALSE   | 0.000121885 |\n| 3    | mut001     | 766   | FALSE   | 3.34E-05    |\n| 4    | mut001     | 216   | FALSE   | 7.24E-06    |\n| 5    | mut001     | 120   | FALSE   | 2.81E-06    |\n| 1    | mut002     | 51484 | FALSE   | 0.003930243 |","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"The relevant columns in this data frame are:","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"barcode: The unique ID that identifies the barcode. This can be anything that helps you identify each barcode.\ncount: The number of raw reads for each particular barcode.\ntime: The time point ID indicating the order in which samples were taken. These must not be in units of time, but simply a serial progression indicating the cycle number.\nneutral: Boolean indicator of whether the barcode belongs to a neutral lineage or not.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"Let's take a look at the data. For this we import the extra package that includes some plotting routines. ","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"warning: Warning\nTo make the package more modular, we did not include plotting functionalities since this can interfere with the installation of the package on remote servers. Instead, the accompanying paper repository includes a module (BayesFitUtils) that we can import to create basic plots using Makie.jl. There are other options within the Julia ecosystem that users might be more familiar with for plotting.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"The BayesFitUtil.viz module has several Makie.jl-based functions to easily display the data. Let's import the necessary plotting libraries","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Import package with useful plotting functions for our dataset\nimport BayesFitUtils\n# Import plotting libraries\nusing CairoMakie\nimport ColorSchemes","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"First, let's plot the barcode frequency trajectories. For this, we use the convenient [BayesFitUtils.viz.bc_time_series!] function.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Initialize figure\nfig = Figure(resolution=(350, 300))\n\n# Add axis\nax = Axis(\n    fig[1, 1], xlabel=\"time [dilution cycle]\", ylabel=\"barcode frequency\", yscale=log10\n)\n\n# Plot mutant barcode trajectories\nBayesFitUtils.viz.bc_time_series!(\n    ax,\n    data[.!(data.neutral), :],\n    quant_col=:freq,\n    zero_lim=0,\n    alpha=0.35\n)\n\n# Plot neutral barcode trajectories\nBayesFitUtils.viz.bc_time_series!(\n    ax,\n    data[data.neutral, :],\n    quant_col=:freq,\n    zero_lim=0,\n    color=ColorSchemes.Blues_9[end],\n)","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"We highlight the neutral barcodes⸺defined to have relative fitness s^(n)=0⸺with dark blue lines. The rest of the light-color lines correspond to individual barcodes.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"(Image: )","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"We can rewrite Eq. (1) as","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"frac1tau ln fracf_t+1^(b)f_t^(b) = \nleft(s^(b) - bars_t right)\ntag2","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"In this form, we can se that the relevant quantity we need to infer the values of the population mean fitness bars_t and the barcode relative fitness s^(b) are not the frequencies themselves, but the log ratio of these frequencies between two adjacent time points. Let's plot this log frequency ratio using the [BayesFitUtils.viz.logfreq_ratio_time_series!] function.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"note: Note\nFor plotting purposes, we will use a naive estimate of the barcode frequencies by normalizing the number of reads by the total number of reads at each time point. In our inference pipeline, we estimate the frequency  given the number of reads to include the uncertainty when converting one to the other.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Initialize figure\nfig = Figure(resolution=(400, 300))\n\n# Add axis\nax = Axis(fig[1, 1], xlabel=\"time [dilution cycle]\", ylabel=\"ln(fₜ₊₁/fₜ)\")\n\n# Plot mutant barcode trajectories\nBayesFitUtils.viz.logfreq_ratio_time_series!(\n    ax,\n    data[.!(data.neutral), :],\n    alpha=0.3\n)\n\n# Plot neutral barcode trajectories\nBayesFitUtils.viz.logfreq_ratio_time_series!(\n    ax,\n    data[data.neutral, :],\n    color=ColorSchemes.Blues_9[end],\n)","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"tip: Tip\nWe expect is to see these log-frequency ratios as relatively flat lines. Especially for the neutral lineages.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"(Image: )","category":"page"},{"location":"#Using-the-neutral-lineages-to-determine-our-priors","page":"BarBay","title":"Using the neutral lineages to determine our priors","text":"","category":"section"},{"location":"","page":"BarBay","title":"BarBay","text":"One of the feature of Bayesian analysis is that we can include prior information into our inference task that encodes our domain expertise. For analysis with a lot of data, as long as the prior is broad-enough, this becomes less relevant. However, although we have a lot of data for multiple barcodes, we are actually in the low-data regime since for each barcode we typically have on the order of 4-5 time point measurements. Thus, defining appropriate priors is important for our inference pipeline. Unfortunately, we do not necessarily measure each genotype multiple times within the same experiment to get a sense of the expected variation in our measurements. An exception to this are the neutral barcodes. These barcodes represent multiple measurement of allegedly the same reference genotype. Therefore, we can use the variability within these measurements to define the priors for our inference. Let's now take the neutrals data and obtain these parameters","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"note: Note\nBarBay.jl includes the function naive_prior within the stats module to compute priors for some of the parameters based on the neutral lineages data. We point the user to the accompanying paper to see details on these prior selection.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Compute naive priors from neutral strains\nnaive_priors = BarBay.stats.naive_prior(data)\n\n# Select standard deviation parameters\ns_pop_prior = hcat(\n    naive_priors[:s_pop_prior],\n    repeat([0.05], length(naive_priors[:s_pop_prior]))\n)\n\nlogσ_pop_prior = hcat(\n    naive_priors[:logσ_pop_prior],\n    repeat([1.0], length(naive_priors[:logσ_pop_prior]))\n)\n\nlogσ_bc_prior = [StatsBase.mean(naive_priors[:logσ_pop_prior]), 1.0]\n\nlogλ_prior = hcat(\n    naive_priors[:logλ_prior],\n    repeat([3.0], length(naive_priors[:logλ_prior]))\n)","category":"page"},{"location":"#Running-the-inference","page":"BarBay","title":"Running the inference","text":"","category":"section"},{"location":"","page":"BarBay","title":"BarBay","text":"With these priors in hand, we can run the inference. For this, we use the BarBay.vi.advi function from the vi module. The main parameters we need to define are:","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":":data: Tidy data frame containing the raw barcode counts.\n:outputname: String defining the pattern for the output file. This can be something related to the dataset. For example, the growth media, or the date of the experiment, of whatever metadata used to distinguish different datasets.\n:model: Bayesian model from the model module that defines the posterior distribution to be sampled.\n:model_kwargs: The parameters required by the model function.\n:advi: Indicating the ADVI implementation with the corresponding number of samples and steps.\nopt: Optimization algorithm for ADVI.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"To speed-up the computation, we will use ReverseDiff.jl as the auto differentiation backend (see Turing.jl documentation for more information on this). Let's import the necessary packages and set the differentiation backend options.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Import library to perform Bayesian inference\nimport Turing\n\n# Import AutoDiff backend\nusing ReverseDiff\n\n# Import Memoization\nusing Memoization\n\n# Set AutoDiff backend\nTuring.setadbackend(:reversediff)\n# Allow system to generate cache to speed up computation\nTuring.setrdcache(true)","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"For this dataset, we use the BarBay.model.fitness_normal model from the model module. Now, we can compile all of the necessary parameters into a dictionary.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Define number of samples and steps\nn_samples = 1\nn_steps = 3_000\n\n# Define function parameters\nparam = Dict(\n    :data => data,\n    :outputname => \"./output/advi_meanfield_\" *\n                   \"$(lpad(n_samples, 2, \"0\"))samples_$(n_steps)steps\",\n    :model => BarBay.model.fitness_normal,\n    :model_kwargs => Dict(\n        :s_pop_prior => s_pop_prior,\n        :logσ_pop_prior => logσ_pop_prior,\n        :logσ_bc_prior => logσ_bc_prior,\n        :s_bc_prior => [0.0, 1.0],\n        :logλ_prior => logλ_prior,\n    ),\n    :advi => Turing.ADVI(n_samples, n_steps),\n    :opt => Turing.TruncatedADAGrad(),\n)","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"Next, we run the inference.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"BarBay.vi.advi(; param...)","category":"page"},{"location":"#Inference-output","page":"BarBay","title":"Inference output","text":"","category":"section"},{"location":"","page":"BarBay","title":"BarBay","text":"After running the inference, the output of is a .csv file of the form","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"| mean                  | std                  | varname   | vartype          | rep | env  | id     |\n|-----------------------|----------------------|-----------|------------------|-----|------|--------|\n| 0.6769813021009923    | 0.019270434240452546 | s̲ₜ[1]    | pop_mean_fitness | R1  | env1 | N/A    |\n| 0.5979391468267903    | 0.023068814619647663 | s̲ₜ[2]    | pop_mean_fitness | R1  | env1 | N/A    |\n| 0.7794031847044068    | 0.021637905105449048 | s̲ₜ[3]    | pop_mean_fitness | R1  | env1 | N/A    |\n| 1.097531601258874     | 0.020140458476711063 | s̲ₜ[4]    | pop_mean_fitness | R1  | env1 | N/A    |\n| -1.1349279694117884   | 0.13764164137709486  | logσ̲ₜ[1] | pop_std          | R1  | env1 | N/A    |\n| -0.8537538300547914   | 0.14427221564497342  | logσ̲ₜ[2] | pop_std          | R1  | env1 | N/A    |\n| -1.0036841099650615   | 0.14850736993662278  | logσ̲ₜ[3] | pop_std          | R1  | env1 | N/A    |\n| -1.0111319869238307   | 0.13429835511246288  | logσ̲ₜ[4] | pop_std          | R1  | env1 | N/A    |\n| -0.023508979117674522 | 0.42814608044575164  | s̲⁽ᵐ⁾[1]  | bc_fitness       | R1  | env1 | mut001 |\n| -0.08443525829413444  | 0.2749553846185592   | s̲⁽ᵐ⁾[2]  | bc_fitness       | R1  | env1 | mut002 |\n| -0.05274382497169921  | 0.1535891599128269   | s̲⁽ᵐ⁾[3]  | bc_fitness       | R1  | env1 | mut003 |\n| 0.14655295685583677   | 0.32454211197027244  | s̲⁽ᵐ⁾[4]  | bc_fitness       | R1  | env1 | mut004 |\n| 0.06093015139986163   | 0.055690708045292796 | s̲⁽ᵐ⁾[5]  | bc_fitness       | R1  | env1 | mut005 |\n| 0.07170404879708663   | 0.2969475992920767   | s̲⁽ᵐ⁾[6]  | bc_fitness       | R1  | env1 | mut006 |\n| 0.03640967790708551   | 0.2664593948070634   | s̲⁽ᵐ⁾[7]  | bc_fitness       | R1  | env1 | mut007 |","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"note: Note\nRecall that our implementation of variational inference assumes the true posterior distribution can be approximated by a multivariate Gaussian distribution with a diagonal covariance matrix. Therefore, the marginal posterior distribution for each of the inferred parameters can be fully parametrized with two numbers: the mean and the standard deviation.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"The columns of this file are","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"mean: The mean of the marginal posterior distribution for the variable.\nstd: The standard deviation of the marginal posterior distribution for the variable.\nvarname: The name of the variable within the Turing.jl model. For the most part, you can ignore this column.\nvartype: Description of the type of parameter. The types are:\npop_mean_fitness: Population mean fitness value s̲ₜ.\npop_error: (Nuisance parameter) Log of standard deviation in the likelihood function for the neutral lineages.\nbc_fitness: Mutant relative fitness s⁽ᵐ⁾.\nbc_hyperfitness: For hierarchical models, mutant hyperparameter that connects the fitness over multiple experimental replicates or multiple genotypes θ⁽ᵐ⁾.\nbc_noncenter: (Nuisance parameter) For hierarchical models, non-centered samples used to connect the experimental replicates to the hyperparameter θ̃⁽ᵐ⁾.\nbc_deviations: (Nuisance parameter) For hierarchical models, samples that define the log of the deviation from the hyperparameter fitness value logτ⁽ᵐ⁾.\nbc_error: (Nuisance parameter) Log of standard deviation in the likelihood function for the mutant lineages.\nfreq: (Nuisance parameter) Log of the Poisson parameter used to define the frequency of each lineage.\nrep: Experimental replicate number.\nenv: Environment for each parameter.\nid: Mutant or neutral strain ID.","category":"page"},{"location":"#Validating-the-inference","page":"BarBay","title":"Validating the inference","text":"","category":"section"},{"location":"","page":"BarBay","title":"BarBay","text":"To visualize the performance of the inference pipeline in fitting the fitness model to data, we can compute the so-called posterior predictive checks (PPC). In short, the PPC consists of repeatedly generating synthetic datasets in agreement with the results from the inference results. In other words, we use the resulting parameter values from the ADVI inference to generate possible datasets in agreement with the inferred values.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"The first step consists of loading the inference results into memory","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Read ADVI results\ndf_advi = CSV.read(\"/path/to/advi/advi_results.csv\", DF.DataFrame)","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"Next, we generate random samples from the posterior distribution. The idea being that we will generate synthetic data for each of these parameter samples  consistent with our data. With a large enough number of samples, we should be able to determine the range where we expect our data to lie.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Define number of samples\nn_samples = 10_000\n\n# Sample from posterior MvNormal\ndf_samples = DF.DataFrame(\n    Random.rand(\n        Distributions.MvNormal(\n            df_advi.mean, LinearAlgebra.Diagonal(df_advi.std .^ 2)\n        ),\n        n_samples\n    )',\n    df_advi.varname\n)","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"Finally, we can use the BarBay.stats.logfreq_ratio_popmean_ppc function for neutral lineages or BarBay.stats.logfreq_ratio_bc_ppc for non-neutral lineages to generate the corresponding posterior predictive checks. In the code that follows, we embed this ppc sampling within the generation of diagnostic plots.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"warning: Warning\nWe remind users that the custom plotting functions are not included in the BarBay.jl package. The following code is only meant to serve as a guidance for users to know how to generate diagnostic plots.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"# Initialize figure\nfig = Figure(resolution=(600, 600))\n\n# Add grid layout for posterior predictive checks\ngl_ppc = fig[1, 1] = GridLayout()\n\n# Define number of posterior predictive check samples\nn_ppc = 500\n# Define quantiles to compute\nqs = [0.95, 0.675, 0.05]\n\n# Define number of rows and columns\nn_row, n_col = [4, 4]\n\n# List example barcodes to plot\nbc_plot = StatsBase.sample(\n    eachrow(DF.sort(df_fitness, :mean)),\n    n_row * n_col,\n    replace=false,\n    ordered=true\n)\n\n# Initialize plot counter\ncounter = 1\n# Loop through rows\nfor row in 1:n_row\n    # Loop through columns\n    for col in 1:n_col\n        # Add axis\n        local ax = Axis(gl_ppc[row, col], aspect=AxisAspect(1.25))\n\n        # Check if first first entry\n        if (row == 1) & (col == 1)\n            # Define dictionary with corresponding parameters for variables\n            # needed for the posterior predictive checks\n            param = Dict(\n                :population_mean_fitness => :s̲ₜ,\n                :population_std_fitness => :σ̲ₜ,\n            )\n\n            # Define colors\n            local colors = get(\n                ColorSchemes.Purples_9, LinRange(0.5, 1.0, length(qs))\n            )\n\n            # Compute posterior predictive checks\n            local ppc_mat = BarBay.stats.logfreq_ratio_popmean_ppc(\n                df_samples, n_ppc; model=:normal, param=param\n            )\n\n            # Define time\n            t = vec(collect(axes(ppc_mat, 2)) .+ 1)\n\n            # Plot posterior predictive checks\n            BayesFitUtils.viz.ppc_time_series!(\n                ax, qs, ppc_mat; colors=colors, time=t\n            )\n\n            # Plot log-frequency ratio of neutrals\n            BayesFitUtils.viz.logfreq_ratio_time_series!(\n                ax,\n                data[data.neutral, :];\n                freq_col=:freq,\n                color=:black,\n                alpha=1.0,\n                linewidth=1.5\n            )\n\n            # Hide axis decorations\n            hidedecorations!.(ax, grid=false)\n\n            ax.title = \"neutral lineages\"\n            # ax.titlesize = 18\n\n            counter += 1\n\n            continue\n        end # if\n\n        # Extract data\n        data_bc = DF.sort(\n            data[data.barcode.==bc_plot[counter].id, :], :time\n        )\n\n        # Define colors\n        local colors = get(ColorSchemes.Blues_9, LinRange(0.5, 1.0, length(qs)))\n\n        # Define dictionary with corresponding parameters for variables needed\n        # for the posterior predictive checks\n        local param = Dict(\n            :bc_mean_fitness => Symbol(bc_plot[counter].varname),\n            :bc_std_fitness => Symbol(\n                replace(bc_plot[counter].varname, \"s\" => \"logσ\")\n            ),\n            :population_mean_fitness => :s̲ₜ,\n        )\n        # Compute posterior predictive checks\n        local ppc_mat = BarBay.stats.logfreq_ratio_bc_ppc(\n            df_samples, n_ppc; model=:normal, param=param\n        )\n        # Plot posterior predictive checks\n        BayesFitUtils.viz.ppc_time_series!(\n            ax, qs, ppc_mat; colors=colors\n        )\n\n        # Add scatter of data\n        scatterlines!(ax, diff(log.(data_bc.freq)), color=:black, linewidth=2.0)\n\n        # Define fitness ranges to display in title\n        vals = [\n            round(bc_plot[counter].mean; sigdigits=2),\n            round(bc_plot[counter].std; sigdigits=2),\n        ]\n\n        # Add title\n        ax.title = \"s⁽ᵐ⁾= $(vals[1])±$(vals[2])\"\n\n        ## == Plot format == ##\n\n        # Hide axis decorations\n        hidedecorations!.(ax, grid=false)\n\n        # Update counter\n        global counter += 1\n    end  # for\nend # for\n\n# Add x-axis label\nLabel(gl_ppc[end, :, Bottom()], \"time points\", fontsize=22)\n# Add y-axis label\nLabel(gl_ppc[:, 1, Left()], \"ln(fₜ₊₁/fₜ)\", rotation=π / 2, fontsize=22)\n# Set spacing\nrowgap!(gl_ppc, 0)\ncolgap!(gl_ppc, 4)","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"(Image: )","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"These are examples of the posterior predictive checks for all neutral lineages (upper left panel) and a subset of representative mutant lineages. Shaded regions represent the 95%, 68%, and 5% credible regions for the data. The reported errors above the plot represent the 68% credible region on the mutant relative fitness marginal distribution.","category":"page"},{"location":"","page":"BarBay","title":"BarBay","text":"As we can see, the data lies within the quantiles, suggesting the inference worked and the model is able to capture the general trend of the barcode trajectories!","category":"page"},{"location":"utils/#utils","page":"utils","title":"utils","text":"","category":"section"},{"location":"utils/","page":"utils","title":"utils","text":"The utils module contains useful functions to handle the raw data and the output results.","category":"page"},{"location":"utils/","page":"utils","title":"utils","text":"The data_to_arrays function takes the tidy dataframes and converts it into the set of arrays used as input for all the models in the model module. This function has different options to build the slight variations needed for each of the models.","category":"page"},{"location":"utils/","page":"utils","title":"utils","text":"BarBay.utils.data_to_arrays","category":"page"},{"location":"utils/#BarBay.utils.data_to_arrays","page":"utils","title":"BarBay.utils.data_to_arrays","text":"data_to_arrays(data; kwargs)\n\nFunction to preprocess the tidy dataframe data into the corresponding inputs for the models in the model submodule.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be used for sampling the model posterior distribution. \n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may include any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will result in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage. The column must contain entries of type Bool.\nrep_col::Union{Nothing,Symbol}=nothing: Column indicating the experimental replicate each measurement belongs to. Default is nothing.\nenv_col::Union{Nothing,Symbol}=nothing: Column indicating the environment in which each measurement was performed. Default is nothing.\ngenotype_col::Union{Nothing,Symbol}=nothing: Column indicating the genotype each barcode belongs to when fitting a hierarchical model on genotypes. Default is nothing.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. The data from this first time point is commonly of much lower quality. Therefore, removing this first time point might result in a better inference.\nverbose::Bool=true: Boolean indicating if printing statements should be made.\n\nReturns\n\ndata_arrays::Dict: Dictionary with the following elements:\nbc_ids: List of barcode IDs in the order they are used for the inference.\nneutral_ids: List of neutral barcode IDs in the order they are used for the inference.\nbc_count: Count time series for each barcode. The options can be:\nMatrix{Int64}: (ntime) × (nbc) matrix with counts. Rows are time points, and columns are barcodes.\nArray{Int64, 3}: The same as the matrix, except the third dimension represents multiple experimental replicates.\nVector{Matrix{Int64}}: List of matrices, one for each experimental replicate. This is when replicates have a different number of time points.\nbc_total: Total number of barcodes per time point. The options can be:\nVector{Int64}: Equivalent to summing each matrix row.\nMatrix{Int64}: Equivalent to summing each row of each slice of the tensor.\nVector{Vector{Int64}}: Equivalent to summing each matrix row.\nn_rep: Number of experimental replicates.\nn_time: Number of time points. The options can be:\nInt64: Number of time points on a single replicate or multiple replicates.\nVector{Int64}: Number of time points per replicate when replicates have different lengths.\nenvs: List of environments. The options can be:\nString: Single placeholder env1\nVector{<:Any}: Environments in the order they were measured.\nvector{Vector{<:Any}}: Environments per replicate when replicates have a different number of time points.\nn_env: Number of environmental conditions.\ngenotypes: List of genotypes for each of the non-neutral barcodes. The options can be:\nN/A: String when no genotype information is given.\nVector{<:Any}: Vector of the corresponding genotype for each of the non-neutral barcodes in the order they are used for the inference.\nn_geno: Number of genotypes. When no genotype information is provided, this defaults to zero.\n\n\n\n\n\n","category":"function"},{"location":"utils/","page":"utils","title":"utils","text":"The advi_to_df function takes the output when fitting a model performing variational inference using the mean-field approximation, i.e., assuming a diagonal covariance matrix.","category":"page"},{"location":"utils/","page":"utils","title":"utils","text":"BarBay.utils.advi_to_df","category":"page"},{"location":"utils/#BarBay.utils.advi_to_df","page":"utils","title":"BarBay.utils.advi_to_df","text":"advi_to_df(data::DataFrames.AbstractDataFrame, dist::Distribution.Sampleable,            vars::Vector{<:Any}; kwargs)\n\nConvert the output of automatic differentiation variational inference (ADVI) to a tidy dataframe.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe used to perform the ADVI inference. See BarBay.vi module for the dataframe requirements.\ndist::Distributions.Sampleable: The ADVI posterior sampleable distribution object.\nvars::Vector{<:Any}: Vector of variable/parameter names from the ADVI run. \n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. The data from this first time point is commonly of much lower quality. Therefore, removing this first time point might result in a better inference.\nn_samples::Int=10_000: Number of posterior samples to draw used for hierarchical models. Default is 10,000.\n\nReturns\n\ndf::DataFrames.DataFrame: DataFrame containing summary statistics of\n\nposterior samples for each parameter. Columns include:     - mean, std: posterior mean and standard deviation for each variable.     - varname: parameter name from the ADVI posterior distribution.     - vartype: Description of the type of parameter. The types are:         - pop_mean_fitness: Population mean fitness value s̲ₜ.         - pop_std: (Nuisance parameter) Log of standard deviation in the           likelihood function for the neutral lineages.         - bc_fitness: Mutant relative fitness s⁽ᵐ⁾.         - bc_hyperfitness: For hierarchical models, mutant hyperparameter           that connects the fitness over multiple experimental replicates or           multiple genotypes θ⁽ᵐ⁾.         - bc_noncenter: (Nuisance parameter) For hierarchical models,           non-centered samples used to connect the experimental replicates to           the hyperparameter θ̃⁽ᵐ⁾.         - bc_deviations: (Nuisance parameter) For hierarchical models,           samples that define the log of the deviation from the hyperparameter           fitness value logτ⁽ᵐ⁾.         - bc_std: (Nuisance parameter) Log of standard deviation in the           likelihood function for the mutant lineages.         - freq: (Nuisance parameter) Log of the Poisson parameter used to           define the frequency of each lineage.     - rep: Experimental replicate number.     - env: Environment for each parameter.     - id: Mutant or neutral strain ID.\n\nNotes\n\nConverts multivariate posterior into summarized dataframe format.\nAdds metadata like parameter type, replicate, strain ID, etc.\nCan handle models with multiple replicates and environments.\nCan handle models with hierarchical structure on genotypes.\nUseful for post-processing ADVI results for further analysis and plotting.\n\n\n\n\n\n","category":"function"},{"location":"vi/#vi","page":"vi","title":"vi","text":"","category":"section"},{"location":"vi/#Primer-on-Variational-Inference","page":"vi","title":"Primer on Variational Inference","text":"","category":"section"},{"location":"vi/","page":"vi","title":"vi","text":"In this section, we will briefly introduce the idea behind variational inference. Recall that any Bayesian inference problem deals with the joint distribution between observations underlinex and unobserved latent variables underlinetheta. This joint distribution can be written as the product of a distribution of the observations underlinex conditioned on the underlinetheta and the marginal distribution of these latent variables, i.e.,","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"pi(underlinex underlinetheta) =\npi(underlinex mid underlinetheta) pi(underlinetheta)\ntag1","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"A Bayesian inference pipeline's objective is to compute the latent variables' posterior probability given a set of observations. This computation is equivalent to updating our prior beliefs about the set of values that the latent variables take after taking in new data. We write this as Bayes theorem","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"pi(underlinetheta mid underlinex) = \nfrac\n        pi(underlinex mid underlinetheta)pi(underlinetheta)\n    \n        pi(underlinex)\n    \ntag2","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"The main technical challenge for working with Eq. 2 comes from the computation of the denominator, also known as the evidence or the marginalized likelihood. The reason computing this term is challenging is because it involves a (potentially) high-dimensional integral of the form","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"pi(underlinex) = \nintcdotsint d^Kunderlinetheta pi(underlinex underlinetheta) = \nintcdotsint d^Kunderlinetheta pi(underlinex mid underlinetheta)\npi(underlinetheta)\ntag3","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"where K is the dimesionality of the underlinetheta vector. Here, the integrals are taken over the support–-the set of values valid for the distribution–-of pi(underlinetheta). However, only a few selected distributions have a closed analytical form; thus, in most cases Eq. 3 must be solved numerically.","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"Integration in high-dimensional spaces can be computationally extremely challenging. For a naive numerical quadrature procedure, integrating over a grid of values for each dimension of underlinetheta comes with an exponential explosion of the number of required grid point evaluations, most of which do not contribute significantly to the integration. To gain visual intuition about this challenge, imagine integrating the function depicted in fig-SI01. If the location of the high-density region (dark peak) is unknown, numerical quadrature requires many grid points to ensure we capture this peak. However, most of the numerical evaluations of the function on the grid points do not contribute significantly to the integral. Therefore, our computational resources are wasted on insignificant evaluations. This only gets worse as the number of dimensions increases since the number of grid point evaluation scales exponentially.","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"Modern Markov Chain Monte Carlo algorithms, such as Hamiltonian Monte Carlo, can efficiently perform this high-dimensional integration by utilizing gradient information from the target density betancourt2017. Nevertheless, these sampling-based methods become prohibitively slow for the number of dimensions our present inference problem presents. Thus, there is a need to find scalable methods for the inference problem in Eq. 2.","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"Variational inference circumvents these technical challenges by proposing an approximate solution to the problem. Instead of working with the posterior distribution in its full glory pi(underlinetheta mid underlinex), let us propose an approximate posterior distribution q_phi that belongs to a distribution family fully parametrized by phi. For example, let us say that the distribution q_phi belongs to the family of multivariate Normal distributions such that phi = (underlinemu underlineunderlineSigma), where underlinemu is the vector of means and underlineunderlineSigma is the covariance matrix. If we replace pi by q_phi, we want q_phi to resemble the original posterior as much as possible. Mathematically, this can be expressed as minimizing a \"distance metric\"–-the Kullback-Leibler (KL) divergence, for example–-between the distributions. Note that we use quotation marks because, formally, the KL divergence is not a distance metric since it is not symmetric. Nevertheless, the variational objective is set to find a distribution q_phi^* such that","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"q_phi^*(underlinetheta) =\nmin_phi D_KLleft(\n    q_phi(underlinetheta) vertvert \n    pi(underlinetheta mid underlinex)\nright)\ntag4","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"where D_KL is the KL divergence. Furthermore, we highlight that the KL divergence is a strictly positive number, i.e.,","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"D_KLleft(\n    q_phi(underlinetheta) vertvert \n    pi(underlinetheta mid underlinex)\nright) geq 0\ntag5","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"as this property will become important later on.","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"At first sight, Eq. 4 does not improve the situation but only introduces further technical complications. After all, the definition of the KL divergence","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"D_KLleft(\n    q_phi(underlinetheta) vertvert \n    pi(underlinetheta mid underlinex)\nright) equiv \nint cdots int d^Kunderlinetheta\nq_phi(underlinetheta)\nln frac\n    q_phi(underlinetheta)\n\n    pi(underlinetheta mid underlinex)\n\ntag6","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"includes the posterior distribution pi(underlinetheta mid underlinex) we are trying to get around. However, let us manipulate Eq. 6 to beat it to a more reasonable form. First, we can use the properties of the logarithms to write","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"D_KLleft(\n    q_phi(underlinetheta) vertvert \n    pi(underlinetheta mid underlinex)\nright) = \nint d^Kunderlinetheta q_phi(underlinetheta)\nln q_phi(underlinetheta) -\nint d^Kunderlinetheta q_phi(underlinetheta)\nln pi(underlinetheta mid underlinex)\ntag7","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"where, for convenience, we write a single integration sign (d^Kunderlinetheta still represents a multi-dimensional differential). For the second term in Eq. 7, we can substitute the term inside the logarithm using Eq. 2. This results in","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"beginaligned\nD_KLleft(\n    q_phi(underlinetheta) vertvert \n    pi(underlinetheta mid underlinex)\nright) = \nint d^Kunderlinetheta q_phi(underlinetheta)\nln q_phi(underlinetheta) \n- int d^Kunderlinetheta q_phi(underlinetheta)\nln left( \n    frac\n        pi(underlinex mid underlinetheta)pi(underlinetheta)\n    \n        pi(underlinex)\n    \nright)\nendaligned\ntag8","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"Again, using the properties of logarithms, we can split Eq. 8, obtaining","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"beginaligned\nD_KLleft(\n    q_phi(underlinetheta) vertvert \n    pi(underlinetheta mid underlinex)\nright) = \nint d^Kunderlinetheta q_phi(underlinetheta)\nln q_phi(underlinetheta) \n-int d^Kunderlinetheta q_phi(underlinetheta)\nln pi(underlinex mid underlinetheta) \n-int d^Kunderlinetheta q_phi(underlinetheta)\nln pi(underlinetheta) \n+int d^Kunderlinetheta q_phi(underlinetheta)\nln pi(underlinex)\nendaligned\ntag9","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"It is convenient to write Eq. 9 as","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"beginaligned\nD_KLleft(\n    q_phi(underlinetheta) vertvert \n    pi(underlinetheta mid underlinex)\nright) = \nint d^Kunderlinetheta q_phi(underlinetheta)\nln frac\n    q_phi(underlinetheta)\n    \n        pi(underlinetheta)\n     \n-int d^Kunderlinetheta q_phi(underlinetheta)\nln pi(underlinex mid underlinetheta) \n+ ln pi(underlinex) \nint d^Kunderlinetheta q_phi(underlinetheta)\nendaligned\ntag10","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"where for the last term, we can take ln pi(underlinex) out of the integral since it does not depend on underlinetheta. Lastly, we utilize two properties:","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"The proposed approximate distribution must be normalized, i.e.,","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"int d^Kunderlinetheta q_phi(underlinetheta) = 1\ntag11","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"The law of the unconscious statistician (LOTUS) establishes that for any","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"probability density function, it must be true that","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"int d^Kunderlinetheta q_phi(underlinetheta)\nf(underlinetheta) = leftlangle \n    f(underlinetheta) \nrightrangle_q_phi\ntag12","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"where leftlanglecdotrightrangle_q_phi is the expected value over the q_phi distribution.","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"Using these two properties, the positivity constraint on the KL divergence in Eq. 5, and the definition of the KL divergence in Eq. 6 we can rewrite Eq. 10 as","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"D_KLleft( \n    q_phi(underlinetheta) vert vert\n    pi(underlinetheta) \nright) -\nleftlangle\n    ln pi(underlinex mid underlinetheta)\nrightrangle_q_phi\ngeq - ln pi(underlinex)\ntag13","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"Multiplying by a minus one, we have the functional form of the so-called evidence lower bound (ELBO) kingma2014,","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"underbrace\n    ln pi(underlinex)\n_textlog evidence geq\nunderbrace\n    leftlangle\n        ln pi(underlinex mid underlinetheta)\n    rightrangle_q_phi -\n    D_KLleft( \n        q_phi(underlinetheta) vert vert\n        pi(underlinetheta) \n    right)\n_textELBO\ntag14","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"Let us recapitulate where we are. We started by presenting the challenge of working with Bayes' theorem, as it requires a high-dimensional integral of the form in Eq. 3. As an alternative, variational inference posits to approximate the posterior distribution pi(underlinetheta mid underlinex) with a parametric distribution q_phi(underlinetheta). By minimizing the KL divergence between these distributions, we arrive at the result in Eq. 14, where the left-hand side–-the log marginalized likelihood or log evidence–-we cannot compute for technical/computational reasons. However, the right-hand side is composed of things we can easily evaluate. We can easily evaluate the log-likelihood ln pi(underlinex mid underlinetheta) and the KL divergence between our proposed approximate distribution q_phi(underlinetheta) and the prior distribution pi(underlinetheta). Moreover, we can compute the gradients of these functions with respect to the parameters of our proposed distribution. This last point implies that we can change the parameters of the proposed distribution to maximize the ELBO. And, although we cannot compute the left-hand side of Eq. 14, we know that however large we make the ELBO, it will always be smaller than (or equal) the log-marginal likelihood. Therefore, the larger we can make the ELBO by modifying the parameters phi, the closer it gets to the log-marginal likelihood, and, as a consequence, the better our proposed distribution q_phi(underlinetheta) gets to the true posterior distribution pi(underlinetheta mid underlinex).","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"In this sense, variational inference turns the intractable numerical integration problem to an optimization routine, for which there are several algorithms  available.","category":"page"},{"location":"vi/#ADVI-algorithm","page":"vi","title":"ADVI algorithm","text":"","category":"section"},{"location":"vi/","page":"vi","title":"vi","text":"To maximize the right-hand side of Eq. 14, the Automatic Differentiation Variational Inference (ADVI) algorithm developed in [kucukelbir2016] takes advantage of advances in probabilistic programming languages to generate a robust method to perform this optimization. Without going into the details of the algorithm implementation, for our purposes, it suffices to say that we define our joint distribution pi(underlinetheta underlinex) as the product defined in Eq. 1. ADVI then proposes an approximate variational distribution q_phi that can either be a multivariate Normal distribution with a diagonal covariance matrix, i.e.,","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"phi = (underlinemu underlineunderlineD)\ntag15","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"where underlineunderlineD is the identity matrix, with the diagonal elements given by the vector of variances underlinesigma^2 for each variable or a full-rank multivariate Normal distribution","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"phi = (underlinemu underlineunderlineSigma)\ntag16","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"Then, the parameters are initialized in some value phi_o. These parameters are iteratively updated by computing the gradient of the ELBO (right-hand side of Eq. 14), hereafter defined as mathcalL, with respect to the parameters, ","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"nabla_phi mathcalL = nabla_underlinemu mathcalL + \nnabla_underlinesigmamathcalL\ntag17","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"and then computing","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"phi_t+1 = phi_t + eta nabla_phi mathcalL\ntag18","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"where eta defines the step size.","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"This short explanation behind the ADVI algorithm is intended only to gain intuition on how the optimal variational distribution q_phi be computed. There are many nuances in the implementation of the ADVI algorithm. We invite the user to look at the original reference for further details.","category":"page"},{"location":"vi/#vi-module","page":"vi","title":"vi module","text":"","category":"section"},{"location":"vi/","page":"vi","title":"vi","text":"This vi module includes (so far) a single function to run variational  inference using the ADVI algorithm implemented in Turing.jl.","category":"page"},{"location":"vi/","page":"vi","title":"vi","text":"Modules = [BarBay.vi]\nOrder   = [:function, :type]","category":"page"},{"location":"vi/#BarBay.vi.advi-Tuple{}","page":"vi","title":"BarBay.vi.advi","text":"advi(; kwargs)\n\nFunction to sample the joint posterior distribution for the fitness value of all mutant and neutral lineages given a time-series barcode count.\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, barcode j measurements over time also get their own individual rows. \n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can be the barcode   sequence, for example.\ntime_col: Column defining the measurement time point.  \ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputname::String: String to name the .csv output file.\nmodel::Function: Turing.jl model defining the posterior distribution from   which to sample (see BarBay.model module). This function must take   as the first four inputs the following:\nR̲̲::Array{Int64}: 2 or 3D array containing the raw barcode counts for   all tracked genotypes. The dimensions of this array represent:  \ndim=1: time.\ndim=2: genotype.\ndim=3 (optional): experimental repeats\nn̲ₜ::VecOrMat{Int64}: Array with the total barcode counts for each time   point (on each experimental repeat, if necessary).\nn_neutral::Int: Number of neutral lineages.\nn_bc::Int: Number of neutral lineages.\n\nOptional Keyword Arguments\n\nmodel_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the\nbarcode identifier. The column may include any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will result in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage. The column must contain entries of type Bool.\nrep_col::Union{Nothing,Symbol}=nothing: Column indicating the experimental replicate each measurement belongs to. Default is nothing.\nenv_col::Union{Nothing,Symbol}=nothing: Column indicating the environment in which each measurement was performed. Default is nothing.\ngenotype_col::Union{Nothing,Symbol}=nothing: Column indicating the genotype each barcode belongs to when fitting a hierarchical model on genotypes. Default is nothing.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. The data from this first time point is commonly of much lower quality. Therefore, removing this first time point might result in a better inference.\nadvi::Turing.AdvancedVI.VariationalInference=Tuing.ADVI(1, 10_000): Variational inference algorithm to infer. Currently, Turing.jl only supports ADVI, where the first input is the number of samples to take (empirically one sample works), and the second is the number of update steps to take.\nopt::Union{Turing.AdvancedVI.DecayedADAGrad,Flux.Optimise.AbstractOptimiser} = Turing.Variational.DecayedADAGrad(1e-2, 1.1, 0.9): Algorithm used to compute the model gradient and update the parameters. Turing.ADVI can take Flux.jl optimizers. But the recommended algorithm in Stan is the default DecayedADAGrad.  \nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\n\nReturns\n\ndf::DataFrames.DataFrame: DataFrame containing summary statistics of posterior samples for each parameter. Columns include:\nmean, std: posterior mean and standard deviation for each variable.\nvarname: parameter name from the ADVI posterior distribution.\nvartype: Description of the type of parameter. The types are:\npop_mean_fitness: Population mean fitness value s̲ₜ.\npop_error: (Nuisance parameter) Log of standard deviation in the likelihood function for the neutral lineages.\nbc_fitness: Mutant relative fitness s⁽ᵐ⁾.\nbc_hyperfitness: For hierarchical models, mutant hyperparameter that connects the fitness over multiple experimental replicates or multiple genotypes θ⁽ᵐ⁾.\nbc_noncenter: (Nuisance parameter) For hierarchical models, non-centered samples used to connect the experimental replicates to the hyperparameter θ̃⁽ᵐ⁾.\nbc_deviations: (Nuisance parameter) For hierarchical models, samples that define the log of the deviation from the hyperparameter fitness value logτ⁽ᵐ⁾.\nbc_error: (Nuisance parameter) Log of standard deviation in the likelihood function for the mutant lineages.\nfreq: (Nuisance parameter) Log of the Poisson parameter used to define the frequency of each lineage.\nrep: Experimental replicate number.\nenv: Environment for each parameter.\nid: Mutant or neutral strain ID.\n\n\n\n\n\n","category":"method"}]
}
